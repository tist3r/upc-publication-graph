{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A2 \n",
    "This notebook containts the preprocessing and data generation steps that were performed to obtain the graph data.\n",
    "\n",
    "First step: created csv files with default commands using the github recommended csv converter: XMLToCSV.py --annotate --neo4j data/dblp.xml data/dblp.dtd data/output.csv\n",
    "\n",
    "## CSV processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import of required packages\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import random\n",
    "import lipsum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords for stopword removal in keyword generation\n",
    "STOP_WORDS = set(stopwords.words('english')) \n",
    "\n",
    "#collection of database community keywords\n",
    "DATABASE_COMMUNITY_KEYWORDS = [\"data management\",\"indexing\", \"data modeling\", \"big data\", \"data processing\", \"data storage\",\"data querying\"]\n",
    "\n",
    "def create_keywords(title, for_db_community=False):\n",
    "    \"\"\"\n",
    "    This functions takes in a title string and returns keywords based on that title. This is done by splitting the title into tokens\n",
    "    and removing the stopwords. Since the database community keywords are usually 2 words long, they are not included this way. To have \n",
    "    enough papers with database community keywords, 1 database community keyword is added randomly to ~30% of papers.\n",
    "    \"\"\"\n",
    "    title = re.sub(r'[^\\w\\s]', \"\", title) #remove punctuation\n",
    "    word_tokens = word_tokenize(title)\n",
    "    keywords = set([w.lower() for w in word_tokens if not w.lower() in STOP_WORDS])\n",
    "\n",
    "    for kw in DATABASE_COMMUNITY_KEYWORDS:\n",
    "        if kw in title:\n",
    "            keywords.add(kw)\n",
    "\n",
    "    if for_db_community:\n",
    "        keywords.add(random.sample(DATABASE_COMMUNITY_KEYWORDS,1)[0])\n",
    "\n",
    "    #add random database community kw to approx 10% of papers\n",
    "    if(random.randrange(0,10,1)<= 1):\n",
    "        keywords.add(random.sample(DATABASE_COMMUNITY_KEYWORDS,1)[0])\n",
    "\n",
    "    return \"|\".join(keywords)\n",
    "\n",
    "def trim_title(title):\n",
    "    \"\"\"\n",
    "    During data loading we discovered that there are very few papers that have an extremly long title string which causes problems during \n",
    "    data loading. Therefore the title character limit is checked and set to 300 characters\n",
    "    \"\"\"\n",
    "    if len(title)>300:\n",
    "        return title[:300]\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "def generate_affiliation(row):\n",
    "    \"\"\"\n",
    "    Generates a random affiliation tuple.\n",
    "    \"\"\"\n",
    "    affil = {\n",
    "        1: \"Company\",\n",
    "        2: \"University\"\n",
    "    }\n",
    "\n",
    "    return f\"{affil.get(random.randint(1,2))} {random.randint(1,30)}\"\n",
    "\n",
    "def generate_publisher(publisher):\n",
    "    \"\"\"\n",
    "    Generates a random publisher string.\n",
    "    \"\"\"\n",
    "    return f\"Publisher {random.randint(1,10)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doi_or_na(ee):\n",
    "    try:\n",
    "        doi = ee.split(\"|\")[0]\n",
    "        #returns the text if it is a doi, na otherwise\n",
    "        if(\"doi\" in ee):\n",
    "            return ee\n",
    "        \n",
    "    except:\n",
    "        print(\"no str found\")\n",
    "    \n",
    "    return pd.NA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Article Preprocessing\n",
    "\n",
    "extracting relevant article information from the articles csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers to keep from the csv\n",
    "KEEP_HEADERS_ARTICLE = [\n",
    "    \"article:ID\",\n",
    "    \"author:string[]\",\n",
    "    \"crossref:string\",#volume-key\n",
    "    \"editor:string[]\",\n",
    "    \"ee:string[]\",\n",
    "    \"journal:string\",#journal:name\n",
    "    \"key:string\", #paper:key\n",
    "    \"number:string\",#volume of the year\n",
    "    \"pages:string\",\n",
    "    \"title:string\", #paper:title\n",
    "    \"volume:string\",#consecutive issue number\n",
    "    \"year:int\", #volume:year,\n",
    "    \"publisher:string\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\2962555990.py:4: DtypeWarning: Columns (6,7,9,10,19,24,26,27,33) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  articles = pd.read_csv(\"data/output_article.csv\", nrows=100000, sep=\";\", names=header)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98652\n"
     ]
    }
   ],
   "source": [
    "header = \"\"\"article:ID;author:string[];author-aux:string;author-orcid:string[];booktitle:string;cdate:date;cdrom:string;cite:string[];cite-label:string[];crossref:string;editor:string[];editor-orcid:string[];ee:string[];ee-type:string[];i:string[];journal:string;key:string;mdate:date;month:string;note:string[];note-label:string;note-type:string[];number:string;pages:string;publisher:string;publnr:string;publtype:string;sub:string[];sup:string[];title:string;title-bibtex:string;tt:string[];url:string[];volume:string;year:int\"\"\".split(\";\")\n",
    "\n",
    "#load data with header\n",
    "articles = pd.read_csv(\"data/output_article.csv\", nrows=100000, sep=\";\", names=header)\n",
    "articles = articles[KEEP_HEADERS_ARTICLE]\n",
    "\n",
    "#typing columns\n",
    "articles[\"crossref:string\"] = articles[\"crossref:string\"].astype(\"string\")\n",
    "articles[\"title:string\"] = articles[\"title:string\"].astype(\"string\")\n",
    "articles[\"author:string[]\"] = articles[\"author:string[]\"].astype(\"string\")\n",
    "pd.to_numeric(articles[\"number:string\"], errors=\"coerce\", downcast=\"integer\")\n",
    "pd.to_numeric(articles[\"year:int\"], downcast=\"integer\")\n",
    "\n",
    "#filter down to year > 1985\n",
    "articles = articles.dropna(subset=\"year:int\")\n",
    "articles = articles[articles[\"year:int\"] > 1985]\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get doi\n",
    "articles[\"doi\"] = articles[\"ee:string[]\"].apply(lambda x: doi_or_na(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18030\n"
     ]
    }
   ],
   "source": [
    "#make database community\n",
    "\n",
    "database_journals = ['Decis. Support Syst.', 'J. Assoc. Inf. Sci. Technol.', 'Big Data Res.']\n",
    "all_journals = ['Web Intell. Agent Syst.', 'Web Intell.' 'IEEE Trans. Hum. Mach. Syst.', \n",
    "                'Comput. Chem. Eng.', 'IEEE Control. Syst. Lett.', 'Inf. Knowl. Syst. Manag.', 'Internet Math.',\n",
    "                'Int. J. Web Inf. Syst.', 'Manag. Sci.' 'Simul.', 'Rev. Iberoam. de Tecnol. del Aprendiz.', 'Dyn. Games Appl.',\n",
    "                'Decis. Support Syst.', 'J. Assoc. Inf. Sci. Technol.', 'Big Data Res.',\n",
    "                'Web Intell. Agent Syst.', 'Web Intell.', 'IEEE Trans. Hum. Mach. Syst.']\n",
    "\n",
    "\n",
    "#filter journals\n",
    "articles[\"keep\"] = articles[\"journal:string\"].apply(lambda x: x in all_journals)\n",
    "articles[\"db_community\"] = articles[\"journal:string\"].apply(lambda x: x in database_journals)\n",
    "\n",
    "articles = articles[articles[\"keep\"]]\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with no journal name\n",
    "articles = articles.dropna(subset=[\"journal:string\"])\n",
    "\n",
    "#drop articles without author\n",
    "articles = articles.dropna(subset=[\"author:string[]\"])\n",
    "\n",
    "#drop with no pages\n",
    "articles = articles.dropna(subset=[\"pages:string\"])\n",
    "\n",
    "#ensure title lenth\n",
    "articles = articles.dropna(subset=[\"title:string\"])\n",
    "articles[\"title:string\"] = articles[\"title:string\"].map(trim_title)\n",
    "\n",
    "#drop rows with missing year\n",
    "articles = articles.dropna(subset=[\"year:int\"])\n",
    "\n",
    "#assert volume 1 for missing volume number\n",
    "articles[\"number:string\"] = articles[\"number:string\"].fillna(1) #set volume number to 1 for missing ones\n",
    "\n",
    "#create volumekey\n",
    "articles[\"volume_key\"] = articles[\"journal:string\"] + articles[\"year:int\"].astype(\"string\") + articles[\"number:string\"].astype(\"string\")\n",
    "\n",
    "#fill missing crossref\n",
    "articles[\"crossref:string\"] = articles[\"crossref:string\"].fillna(articles[\"volume_key\"])\n",
    "\n",
    "#create corresponding_author\n",
    "articles[\"corresponding_author\"] = articles[\"author:string[]\"].apply(lambda x: x.split(\"|\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate keywords\n",
    "articles[\"keywords\"] = articles.apply(lambda row: create_keywords(row[\"title:string\"], row[\"db_community\"]), axis=1)\n",
    "articles[\"in_db_community\"] = articles[\"keywords\"].apply(lambda x: len(set(DATABASE_COMMUNITY_KEYWORDS).intersection(set(x.split(\"|\"))))>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate publishers\n",
    "articles[\"publisher\"] = articles[\"publisher:string\"].apply(generate_publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>crossref:string</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>journal:string</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>...</th>\n",
       "      <th>year:int</th>\n",
       "      <th>publisher:string</th>\n",
       "      <th>doi</th>\n",
       "      <th>keep</th>\n",
       "      <th>db_community</th>\n",
       "      <th>volume_key</th>\n",
       "      <th>corresponding_author</th>\n",
       "      <th>keywords</th>\n",
       "      <th>in_db_community</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>32735</td>\n",
       "      <td>Frank McCarey|Mel Ó Cinnéide|Nicholas Kushmerick</td>\n",
       "      <td>Web Intell. Agent Syst.20081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3233/WIA-2008-0129</td>\n",
       "      <td>Web Intell. Agent Syst.</td>\n",
       "      <td>journals/wias/McCareyCK08</td>\n",
       "      <td>1</td>\n",
       "      <td>59-81</td>\n",
       "      <td>Knowledge reuse for software reuse.</td>\n",
       "      <td>...</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3233/WIA-2008-0129</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Web Intell. Agent Syst.20081</td>\n",
       "      <td>Frank McCarey</td>\n",
       "      <td>reuse|big data|software|knowledge</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>32740</td>\n",
       "      <td>Larry M. Manevitz|Malik Yousef</td>\n",
       "      <td>Web Intell. Agent Syst.20042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://content.iospress.com/articles/web-intel...</td>\n",
       "      <td>Web Intell. Agent Syst.</td>\n",
       "      <td>journals/wias/ManevitzY04</td>\n",
       "      <td>2</td>\n",
       "      <td>137-144</td>\n",
       "      <td>A web navigation system based on a neural netw...</td>\n",
       "      <td>...</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Web Intell. Agent Syst.20042</td>\n",
       "      <td>Larry M. Manevitz</td>\n",
       "      <td>usermodel|documents|based|big data|system|trai...</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>32747</td>\n",
       "      <td>Chih-Ming Chen</td>\n",
       "      <td>Web Intell. Agent Syst.20041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://content.iospress.com/articles/web-intel...</td>\n",
       "      <td>Web Intell. Agent Syst.</td>\n",
       "      <td>journals/wias/Chen04</td>\n",
       "      <td>1</td>\n",
       "      <td>21-38</td>\n",
       "      <td>Incremental personalized web page mining utili...</td>\n",
       "      <td>...</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Web Intell. Agent Syst.20041</td>\n",
       "      <td>Chih-Ming Chen</td>\n",
       "      <td>personalized|hcmac|mining|page|data processing...</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4643</th>\n",
       "      <td>32748</td>\n",
       "      <td>Haralambos Mouratidis|Manuel Kolp|Paolo Giorgi...</td>\n",
       "      <td>Web Intell. Agent Syst.20101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3233/WIA-2010-0182</td>\n",
       "      <td>Web Intell. Agent Syst.</td>\n",
       "      <td>journals/wias/MouratidisKGF10</td>\n",
       "      <td>1</td>\n",
       "      <td>99-122</td>\n",
       "      <td>An architectural description language for secu...</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3233/WIA-2010-0182</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Web Intell. Agent Syst.20101</td>\n",
       "      <td>Haralambos Mouratidis</td>\n",
       "      <td>description|language|indexing|architectural|sy...</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>32758</td>\n",
       "      <td>Lin Li|Rui Zhang|Wenfeng Zhao|Xiaojie Li|Xicha...</td>\n",
       "      <td>Web Intell.20221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3233/WEB-210478</td>\n",
       "      <td>Web Intell.</td>\n",
       "      <td>journals/wias/HuZLYLZZL22</td>\n",
       "      <td>1</td>\n",
       "      <td>21-35</td>\n",
       "      <td>Conflict detection in Task Heterogeneous Infor...</td>\n",
       "      <td>...</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3233/WEB-210478</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Web Intell.20221</td>\n",
       "      <td>Lin Li</td>\n",
       "      <td>detection|information|task|heterogeneous|data ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article:ID                                    author:string[]  \\\n",
       "4630       32735   Frank McCarey|Mel Ó Cinnéide|Nicholas Kushmerick   \n",
       "4635       32740                     Larry M. Manevitz|Malik Yousef   \n",
       "4642       32747                                     Chih-Ming Chen   \n",
       "4643       32748  Haralambos Mouratidis|Manuel Kolp|Paolo Giorgi...   \n",
       "4653       32758  Lin Li|Rui Zhang|Wenfeng Zhao|Xiaojie Li|Xicha...   \n",
       "\n",
       "                   crossref:string editor:string[]  \\\n",
       "4630  Web Intell. Agent Syst.20081             NaN   \n",
       "4635  Web Intell. Agent Syst.20042             NaN   \n",
       "4642  Web Intell. Agent Syst.20041             NaN   \n",
       "4643  Web Intell. Agent Syst.20101             NaN   \n",
       "4653              Web Intell.20221             NaN   \n",
       "\n",
       "                                            ee:string[]  \\\n",
       "4630              https://doi.org/10.3233/WIA-2008-0129   \n",
       "4635  http://content.iospress.com/articles/web-intel...   \n",
       "4642  http://content.iospress.com/articles/web-intel...   \n",
       "4643              https://doi.org/10.3233/WIA-2010-0182   \n",
       "4653                 https://doi.org/10.3233/WEB-210478   \n",
       "\n",
       "               journal:string                     key:string number:string  \\\n",
       "4630  Web Intell. Agent Syst.      journals/wias/McCareyCK08             1   \n",
       "4635  Web Intell. Agent Syst.      journals/wias/ManevitzY04             2   \n",
       "4642  Web Intell. Agent Syst.           journals/wias/Chen04             1   \n",
       "4643  Web Intell. Agent Syst.  journals/wias/MouratidisKGF10             1   \n",
       "4653              Web Intell.      journals/wias/HuZLYLZZL22             1   \n",
       "\n",
       "     pages:string                                       title:string  ...  \\\n",
       "4630        59-81                Knowledge reuse for software reuse.  ...   \n",
       "4635      137-144  A web navigation system based on a neural netw...  ...   \n",
       "4642        21-38  Incremental personalized web page mining utili...  ...   \n",
       "4643       99-122  An architectural description language for secu...  ...   \n",
       "4653        21-35  Conflict detection in Task Heterogeneous Infor...  ...   \n",
       "\n",
       "     year:int  publisher:string                                    doi  keep  \\\n",
       "4630     2008               NaN  https://doi.org/10.3233/WIA-2008-0129  True   \n",
       "4635     2004               NaN                                   <NA>  True   \n",
       "4642     2004               NaN                                   <NA>  True   \n",
       "4643     2010               NaN  https://doi.org/10.3233/WIA-2010-0182  True   \n",
       "4653     2022               NaN     https://doi.org/10.3233/WEB-210478  True   \n",
       "\n",
       "      db_community                    volume_key   corresponding_author  \\\n",
       "4630         False  Web Intell. Agent Syst.20081          Frank McCarey   \n",
       "4635         False  Web Intell. Agent Syst.20042      Larry M. Manevitz   \n",
       "4642         False  Web Intell. Agent Syst.20041         Chih-Ming Chen   \n",
       "4643         False  Web Intell. Agent Syst.20101  Haralambos Mouratidis   \n",
       "4653         False              Web Intell.20221                 Lin Li   \n",
       "\n",
       "                                               keywords in_db_community  \\\n",
       "4630                  reuse|big data|software|knowledge            True   \n",
       "4635  usermodel|documents|based|big data|system|trai...            True   \n",
       "4642  personalized|hcmac|mining|page|data processing...            True   \n",
       "4643  description|language|indexing|architectural|sy...            True   \n",
       "4653  detection|information|task|heterogeneous|data ...            True   \n",
       "\n",
       "        publisher  \n",
       "4630  Publisher 9  \n",
       "4635  Publisher 3  \n",
       "4642  Publisher 4  \n",
       "4643  Publisher 7  \n",
       "4653  Publisher 3  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[articles[\"in_db_community\"]].head()\n",
    "#print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "articles.to_csv(\"data/articles_preprocessed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Inproceedings preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_HEADER_INPROCEEDING = [\n",
    "    \"inproceedings:ID\",\n",
    "    \"author:string[]\",\n",
    "    \"booktitle:string\",#conference/forum title\n",
    "    \"crossref:string[]\",#proceeding key\n",
    "    \"editor:string[]\",\n",
    "    \"ee:string[]\",\n",
    "    \"key:string\",#inproceedings key\n",
    "    \"number:string\",\n",
    "    \"pages:string\",\n",
    "    \"title:string\",\n",
    "    \"volume:int\",\n",
    "    \"year:int\"#year_held\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\199994687.py:2: DtypeWarning: Columns (5,12,16,17,21,22,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  inproceedings = pd.read_csv(\"data/output_inproceedings.csv\", nrows=100000, sep=\";\", names=header)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99405\n"
     ]
    }
   ],
   "source": [
    "header = \"\"\"inproceedings:ID;author:string[];author-aux:string[];author-orcid:string[];booktitle:string;cdrom:string[];cite:string[];cite-label:string[];crossref:string[];editor:string[];editor-orcid:string[];ee:string[];ee-type:string[];i:string[];key:string;mdate:date;month:string;note:string;note-type:string;number:string;pages:string;publtype:string;sub:string[];sup:string[];title:string;title-bibtex:string;tt:string;url:string;volume:int;year:int\"\"\".split(\";\")\n",
    "inproceedings = pd.read_csv(\"data/output_inproceedings.csv\", nrows=100000, sep=\";\", names=header)\n",
    "inproceedings = inproceedings[KEEP_HEADER_INPROCEEDING]\n",
    "\n",
    "#typing columns\n",
    "inproceedings[\"crossref:string[]\"] = inproceedings[\"crossref:string[]\"].astype(\"string\")\n",
    "inproceedings[\"title:string\"] = inproceedings[\"title:string\"].astype(\"string\")\n",
    "pd.to_numeric(inproceedings[\"number:string\"], errors=\"coerce\", downcast=\"integer\")\n",
    "pd.to_numeric(inproceedings[\"year:int\"], downcast=\"integer\")\n",
    "inproceedings[\"author:string[]\"] = inproceedings[\"author:string[]\"].astype(\"string\")\n",
    "\n",
    "#only keep > 1985\n",
    "inproceedings = inproceedings.dropna(subset=\"year:int\")\n",
    "\n",
    "inproceedings = inproceedings.dropna(subset=\"booktitle:string\")\n",
    "inproceedings = inproceedings[inproceedings[\"year:int\"] > 1985]\n",
    "print(len(inproceedings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756\n",
      "Advanced Database Systems\n",
      "Databases in Telecommunications\n",
      "ILPS Workshop: Constraints and Databases\n"
     ]
    }
   ],
   "source": [
    "conference_names = inproceedings[\"booktitle:string\"].unique()\n",
    "\n",
    "print(len(conference_names))\n",
    "\n",
    "for name in conference_names:\n",
    "    if \"database\" in name.lower():\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SWEE', 'Text Understanding in LILOG', 'Advanced Database Systems', 'Constraint Programming', 'NIPS Causality: Objectives and Assessment', 'AISTATS', 'COLT', 'Active Learning and Experimental Design @ AISTATS', 'WAPA', 'ACML', 'KDD Cup', 'FSDM', 'ICGI', 'ICML Unsupervised and Transfer Learning', 'MLSB', 'NIPS Mini-Symposium on Causality in Time Series', 'Yahoo! Learning to Rank Challenge', 'WCCI Causation and Prediction Challenge', 'Gaussian Processes in Practice', 'ICML On-line Trading of Exploration and Exploitation', 'ACML', 'Advanced Database Systems', 'Databases in Telecommunications', 'ILPS Workshop: Constraints and Databases', 'Text Understanding in LILOG', 'COLT']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "database_conferences = list(conference_names[0:20])\n",
    "database_conferences.extend([\"ACML\", \"Advanced Database Systems\", \"Databases in Telecommunications\", \"ILPS Workshop: Constraints and Databases\", \"Text Understanding in LILOG\", 'COLT'])\n",
    "print(database_conferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#database_conferences = [\"ACML\", \"Advanced Database Systems\", \"Databases in Telecommunications\", \"ILPS Workshop: Constraints and Databases\", \"Text Understanding in LILOG\", 'COLT']\n",
    "all_conferences = conference_names[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    COUNTER = 0\n",
    "\n",
    "def _keep(conf_name):\n",
    "    Counter.COUNTER = Counter.COUNTER + 1\n",
    "    return conf_name in all_conferences or Counter.COUNTER <= 10000\n",
    "\n",
    "\n",
    "inproceedings[\"keep\"] = inproceedings[\"booktitle:string\"].apply(lambda x: _keep(x))\n",
    "\n",
    "inproceedings.head()\n",
    "inproceedings[\"db_community\"] = inproceedings[\"booktitle:string\"].apply(lambda x: x in database_conferences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n"
     ]
    }
   ],
   "source": [
    "#filter \n",
    "inproceedings = inproceedings[inproceedings[\"keep\"]]\n",
    "print(len(inproceedings[inproceedings[\"db_community\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inproceedings:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:int</th>\n",
       "      <th>year:int</th>\n",
       "      <th>keep</th>\n",
       "      <th>db_community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>Arnon Rosenthal</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>conf/swee/1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.mitre.org/support/swee/rosenthal.html</td>\n",
       "      <td>www/org/mitre/future</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159865</td>\n",
       "      <td>Sven Lorenz|Toni Bollinger|Udo Pletat</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_72</td>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402-427</td>\n",
       "      <td>The LILOG Inference Engine.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159866</td>\n",
       "      <td>Geoffrey Simmons|Kai-Uwe Carstensen</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_83</td>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632-644</td>\n",
       "      <td>Why a Hill Can't be a Valley: Representing Ges...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159867</td>\n",
       "      <td>David W. Flater|Yelena Yesha</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>journals/lncs/1993-759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_13</td>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259-276</td>\n",
       "      <td>Towards Flexible Distributed Information Retri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>159868</td>\n",
       "      <td>Claus-Rainer Rollinger|Otthein Herzog</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_46</td>\n",
       "      <td>journals/lncs/RollingerH91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-13</td>\n",
       "      <td>Introducing LILOG.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inproceedings:ID                        author:string[]  \\\n",
       "0               555                        Arnon Rosenthal   \n",
       "2            159865  Sven Lorenz|Toni Bollinger|Udo Pletat   \n",
       "3            159866    Geoffrey Simmons|Kai-Uwe Carstensen   \n",
       "4            159867           David W. Flater|Yelena Yesha   \n",
       "5            159868  Claus-Rainer Rollinger|Otthein Herzog   \n",
       "\n",
       "              booktitle:string       crossref:string[]  editor:string[]  \\\n",
       "0                         SWEE          conf/swee/1998              NaN   \n",
       "2  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "3  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "4    Advanced Database Systems  journals/lncs/1993-759              NaN   \n",
       "5  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "\n",
       "                                        ee:string[]  \\\n",
       "0  http://www.mitre.org/support/swee/rosenthal.html   \n",
       "2          https://doi.org/10.1007/3-540-54594-8_72   \n",
       "3          https://doi.org/10.1007/3-540-54594-8_83   \n",
       "4          https://doi.org/10.1007/3-540-57507-3_13   \n",
       "5          https://doi.org/10.1007/3-540-54594-8_46   \n",
       "\n",
       "                    key:string  number:string pages:string  \\\n",
       "0         www/org/mitre/future            NaN          NaN   \n",
       "2  journals/lncs/BollingerLP91            NaN      402-427   \n",
       "3  journals/lncs/CarstensenS91            NaN      632-644   \n",
       "4      journals/lncs/FlaterY93            NaN      259-276   \n",
       "5   journals/lncs/RollingerH91            NaN         3-13   \n",
       "\n",
       "                                        title:string  volume:int  year:int  \\\n",
       "0  The Future of Classic Data Administration: Obj...         NaN      1998   \n",
       "2                        The LILOG Inference Engine.         NaN      1991   \n",
       "3  Why a Hill Can't be a Valley: Representing Ges...         NaN      1991   \n",
       "4  Towards Flexible Distributed Information Retri...         NaN      1993   \n",
       "5                                 Introducing LILOG.         NaN      1991   \n",
       "\n",
       "   keep  db_community  \n",
       "0  True          True  \n",
       "2  True          True  \n",
       "3  True          True  \n",
       "4  True          True  \n",
       "5  True          True  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inproceedings.head()\n",
    "#print(inproceedings[\"booktitle:string\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no str found\n",
      "no str found\n",
      "no str found\n"
     ]
    }
   ],
   "source": [
    "#crossref is required to get the information from proceedings - thus crossref na are dropped\n",
    "inproceedings = inproceedings.dropna(subset=[\"crossref:string[]\"])\n",
    "\n",
    "#drop articles without author\n",
    "inproceedings = inproceedings.dropna(subset=[\"author:string[]\"])\n",
    "\n",
    "#create corresponding_author\n",
    "inproceedings[\"corresponding_author\"] = inproceedings[\"author:string[]\"].apply(lambda x: x.split(\"|\")[0])\n",
    "\n",
    "#we have enough elements so drop the ones without pages\n",
    "inproceedings = inproceedings.dropna(subset=[\"pages:string\"])\n",
    "\n",
    "#create doi\n",
    "inproceedings[\"doi\"] = inproceedings[\"ee:string[]\"].apply(doi_or_na)\n",
    "\n",
    "#ensure title lenth\n",
    "inproceedings = inproceedings.dropna(subset=[\"title:string\"])\n",
    "inproceedings[\"title:string\"] = inproceedings[\"title:string\"].map(trim_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9981\n"
     ]
    }
   ],
   "source": [
    "print(len(inproceedings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate keywords\n",
    "inproceedings[\"keywords\"] = inproceedings.apply(lambda x: create_keywords(x[\"title:string\"], x[\"db_community\"]), axis = 1)\n",
    "inproceedings[\"is_workshop\"] = inproceedings[\"title:string\"].apply(lambda x: \"workshop\" in x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(inproceedings[inproceedings[\"is_workshop\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inproceedings:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:int</th>\n",
       "      <th>year:int</th>\n",
       "      <th>keep</th>\n",
       "      <th>db_community</th>\n",
       "      <th>corresponding_author</th>\n",
       "      <th>doi</th>\n",
       "      <th>keywords</th>\n",
       "      <th>is_workshop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159865</td>\n",
       "      <td>Sven Lorenz|Toni Bollinger|Udo Pletat</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_72</td>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402-427</td>\n",
       "      <td>The LILOG Inference Engine.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Sven Lorenz</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_72</td>\n",
       "      <td>data modeling|inference|engine|lilog</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159866</td>\n",
       "      <td>Geoffrey Simmons|Kai-Uwe Carstensen</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_83</td>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632-644</td>\n",
       "      <td>Why a Hill Can't be a Valley: Representing Ges...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Geoffrey Simmons</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_83</td>\n",
       "      <td>gestalt|object|valley|cant|data processing|rep...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159867</td>\n",
       "      <td>David W. Flater|Yelena Yesha</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>journals/lncs/1993-759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_13</td>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259-276</td>\n",
       "      <td>Towards Flexible Distributed Information Retri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>David W. Flater</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_13</td>\n",
       "      <td>flexible|retrieval|information|data processing...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>159868</td>\n",
       "      <td>Claus-Rainer Rollinger|Otthein Herzog</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_46</td>\n",
       "      <td>journals/lncs/RollingerH91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-13</td>\n",
       "      <td>Introducing LILOG.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Claus-Rainer Rollinger</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_46</td>\n",
       "      <td>lilog|data processing|introducing</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>159869</td>\n",
       "      <td>Bharat K. Bhargava|Jagannathan Srinivasan|Pras...</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>journals/lncs/1993-759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_5</td>\n",
       "      <td>journals/lncs/BhargavaJSD93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-103</td>\n",
       "      <td>Transition From A Relation To Object Model Imp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Bharat K. Bhargava</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_5</td>\n",
       "      <td>object|transition|model|big data|implementatio...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inproceedings:ID                                    author:string[]  \\\n",
       "2            159865              Sven Lorenz|Toni Bollinger|Udo Pletat   \n",
       "3            159866                Geoffrey Simmons|Kai-Uwe Carstensen   \n",
       "4            159867                       David W. Flater|Yelena Yesha   \n",
       "5            159868              Claus-Rainer Rollinger|Otthein Herzog   \n",
       "6            159869  Bharat K. Bhargava|Jagannathan Srinivasan|Pras...   \n",
       "\n",
       "              booktitle:string       crossref:string[]  editor:string[]  \\\n",
       "2  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "3  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "4    Advanced Database Systems  journals/lncs/1993-759              NaN   \n",
       "5  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "6    Advanced Database Systems  journals/lncs/1993-759              NaN   \n",
       "\n",
       "                                ee:string[]                   key:string  \\\n",
       "2  https://doi.org/10.1007/3-540-54594-8_72  journals/lncs/BollingerLP91   \n",
       "3  https://doi.org/10.1007/3-540-54594-8_83  journals/lncs/CarstensenS91   \n",
       "4  https://doi.org/10.1007/3-540-57507-3_13      journals/lncs/FlaterY93   \n",
       "5  https://doi.org/10.1007/3-540-54594-8_46   journals/lncs/RollingerH91   \n",
       "6   https://doi.org/10.1007/3-540-57507-3_5  journals/lncs/BhargavaJSD93   \n",
       "\n",
       "   number:string pages:string  \\\n",
       "2            NaN      402-427   \n",
       "3            NaN      632-644   \n",
       "4            NaN      259-276   \n",
       "5            NaN         3-13   \n",
       "6            NaN       87-103   \n",
       "\n",
       "                                        title:string  volume:int  year:int  \\\n",
       "2                        The LILOG Inference Engine.         NaN      1991   \n",
       "3  Why a Hill Can't be a Valley: Representing Ges...         NaN      1991   \n",
       "4  Towards Flexible Distributed Information Retri...         NaN      1993   \n",
       "5                                 Introducing LILOG.         NaN      1991   \n",
       "6  Transition From A Relation To Object Model Imp...         NaN      1993   \n",
       "\n",
       "   keep  db_community    corresponding_author  \\\n",
       "2  True          True             Sven Lorenz   \n",
       "3  True          True        Geoffrey Simmons   \n",
       "4  True          True         David W. Flater   \n",
       "5  True          True  Claus-Rainer Rollinger   \n",
       "6  True          True      Bharat K. Bhargava   \n",
       "\n",
       "                                        doi  \\\n",
       "2  https://doi.org/10.1007/3-540-54594-8_72   \n",
       "3  https://doi.org/10.1007/3-540-54594-8_83   \n",
       "4  https://doi.org/10.1007/3-540-57507-3_13   \n",
       "5  https://doi.org/10.1007/3-540-54594-8_46   \n",
       "6   https://doi.org/10.1007/3-540-57507-3_5   \n",
       "\n",
       "                                            keywords  is_workshop  \n",
       "2               data modeling|inference|engine|lilog        False  \n",
       "3  gestalt|object|valley|cant|data processing|rep...        False  \n",
       "4  flexible|retrieval|information|data processing...        False  \n",
       "5                  lilog|data processing|introducing        False  \n",
       "6  object|transition|model|big data|implementatio...        False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inproceedings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "inproceedings.to_csv(\"data/inproceedings_preprocessed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Proceedings csv Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_HEADER_PROCEEDING = [\n",
    "    \"proceedings:ID\",\n",
    "    \"booktitle:string\",\n",
    "    \"editor:string[]\",\n",
    "    \"ee:string[]\",\n",
    "    \"key:string\",\n",
    "    \"number:string\",\n",
    "    \"title:string\",\n",
    "    \"volume:string\",\n",
    "    \"year:int\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\3556115800.py:2: DtypeWarning: Columns (1,2,4,5,10,12,13,18,19,22,23,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  proceedings = pd.read_csv(\"data/output_proceedings.csv\", nrows=100000, sep=\";\", names=header)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        1999\n",
       "1        2015\n",
       "2        2013\n",
       "3        2014\n",
       "4        2019\n",
       "         ... \n",
       "53876    2013\n",
       "53877    2007\n",
       "53878    1999\n",
       "53879    2017\n",
       "53880    2010\n",
       "Name: year:int, Length: 53881, dtype: int16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = \"\"\"proceedings:ID;address:string;author:string[];booktitle:string;cite:string[];cite-label:string[];editor:string[];editor-orcid:string[];ee:string[];ee-type:string[];i:string;isbn:string[];isbn-type:string[];journal:string;key:string;mdate:date;note:string[];note-type:string;number:string;pages:string;publisher:string[];publisher-href:string;publtype:string;school:string;series:string[];series-href:string[];sub:string;sup:string[];title:string;url:string[];volume:string;year:int\"\"\".split(\";\")\n",
    "proceedings = pd.read_csv(\"data/output_proceedings.csv\", nrows=100000, sep=\";\", names=header)\n",
    "proceedings = proceedings[KEEP_HEADER_PROCEEDING]\n",
    "\n",
    "#typing columns\n",
    "proceedings[\"title:string\"] = proceedings[\"title:string\"].astype(\"string\")\n",
    "pd.to_numeric(proceedings[\"number:string\"], errors=\"coerce\", downcast=\"integer\")\n",
    "pd.to_numeric(proceedings[\"year:int\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proceedings:ID</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:string</th>\n",
       "      <th>year:int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>MMB (Kurzvorträge)</td>\n",
       "      <td>Dieter Baum|Norbert Th. Müller|Richard Rödler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tr/trier/MI99-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MMB '99, Messung, Modellierung und Bewertung v...</td>\n",
       "      <td>99-16</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amir Hossein Alavi|Amir Hossein Gandomi|Conor ...</td>\n",
       "      <td>https://doi.org/10.1007/978-3-319-20883-1</td>\n",
       "      <td>reference/genetic/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handbook of Genetic Programming Applications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankur Agarwal|Borko Furht</td>\n",
       "      <td>https://doi.org/10.1007/978-1-4614-8495-0</td>\n",
       "      <td>reference/med/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handbook of Medical and Healthcare Technologies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103589</td>\n",
       "      <td>Trans. Computational Collective Intelligence</td>\n",
       "      <td>Ngoc Thanh Nguyen</td>\n",
       "      <td>https://doi.org/10.1007/978-3-662-44509-9</td>\n",
       "      <td>journals/tcci/2014-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transactions on Computational Collective Intel...</td>\n",
       "      <td>8615</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcin Hernes|Ngoc Thanh Nguyen|Ryszard Kowalczyk</td>\n",
       "      <td>https://doi.org/10.1007/978-3-662-58611-2</td>\n",
       "      <td>journals/tcci/2019-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transactions on Computational Collective Intel...</td>\n",
       "      <td>11370</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proceedings:ID                              booktitle:string  \\\n",
       "0             461                            MMB (Kurzvorträge)   \n",
       "1            2240                                           NaN   \n",
       "2           13516                                           NaN   \n",
       "3          103589  Trans. Computational Collective Intelligence   \n",
       "4          103594                                           NaN   \n",
       "\n",
       "                                     editor:string[]  \\\n",
       "0      Dieter Baum|Norbert Th. Müller|Richard Rödler   \n",
       "1  Amir Hossein Alavi|Amir Hossein Gandomi|Conor ...   \n",
       "2                          Ankur Agarwal|Borko Furht   \n",
       "3                                  Ngoc Thanh Nguyen   \n",
       "4  Marcin Hernes|Ngoc Thanh Nguyen|Ryszard Kowalczyk   \n",
       "\n",
       "                                 ee:string[]              key:string  \\\n",
       "0                                        NaN        tr/trier/MI99-17   \n",
       "1  https://doi.org/10.1007/978-3-319-20883-1  reference/genetic/2015   \n",
       "2  https://doi.org/10.1007/978-1-4614-8495-0      reference/med/2013   \n",
       "3  https://doi.org/10.1007/978-3-662-44509-9   journals/tcci/2014-14   \n",
       "4  https://doi.org/10.1007/978-3-662-58611-2   journals/tcci/2019-32   \n",
       "\n",
       "  number:string                                       title:string  \\\n",
       "0           NaN  MMB '99, Messung, Modellierung und Bewertung v...   \n",
       "1           NaN       Handbook of Genetic Programming Applications   \n",
       "2           NaN    Handbook of Medical and Healthcare Technologies   \n",
       "3           NaN  Transactions on Computational Collective Intel...   \n",
       "4           NaN  Transactions on Computational Collective Intel...   \n",
       "\n",
       "  volume:string  year:int  \n",
       "0         99-16      1999  \n",
       "1           NaN      2015  \n",
       "2           NaN      2013  \n",
       "3          8615      2014  \n",
       "4         11370      2019  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proceedings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop where title not present\n",
    "proceedings = proceedings.dropna(subset=[\"title:string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849\n"
     ]
    }
   ],
   "source": [
    "#filter proceedings down to relevant subset from selected papers\n",
    "conference_crossrefs = inproceedings[\"crossref:string[]\"].unique()\n",
    "proceedings[\"in_selected_ip_subset\"] = proceedings[\"key:string\"].apply(lambda x: True if x in conference_crossrefs else pd.NA)\n",
    "proceedings = proceedings.dropna(subset=[\"in_selected_ip_subset\"])\n",
    "print(sum(proceedings[\"in_selected_ip_subset\"]))\n",
    "\n",
    "#create doi\n",
    "proceedings[\"doi\"] = proceedings[\"ee:string[]\"].apply(doi_or_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edition where possible\n",
    "def get_edition(volume):\n",
    "    try:\n",
    "        return volume.split(\"-\")[1]\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "proceedings[\"edition\"] = proceedings[\"volume:string\"].map(get_edition)\n",
    "proceedings[\"edition\"] = proceedings[\"edition\"].fillna(proceedings[\"volume:string\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "proceedings.to_csv(\"data/proceedings_preprocessed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "To be able to reflect everything that is required as described in the Lab text, we have to generate some additional data\n",
    "\n",
    "### 1. Create citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paper keys and years from articles\n",
    "article_keys = articles[[\"key:string\",\"year:int\"]]\n",
    "#print(article_keys)\n",
    "\n",
    "ip_keys = inproceedings[[\"key:string\",\"year:int\"]]\n",
    "#print(ip_keys)\n",
    "\n",
    "## union both\n",
    "cite_keys = pd.concat([article_keys, ip_keys])\n",
    "#cite_keys[\"year:int\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_citations(df, year):\n",
    "    \"\"\"\n",
    "    Selects 5 to 15 random citations from papers that have been published earlier than the current paper.\n",
    "    \"\"\"\n",
    "    no_citations = random.randint(5,15)\n",
    "\n",
    "    df = df[df[\"year:int\"] < year]\n",
    "\n",
    "    try:\n",
    "        citation_keys = df[\"key:string\"].sample(no_citations, random_state=42).tolist()\n",
    "    except ValueError:\n",
    "        #for the oldest papers obviously no citations can be selected, thus they won't have citations.\n",
    "        print(f\"could not make sample for year {year}\")\n",
    "        citation_keys = []\n",
    "\n",
    "    return citation_keys    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n"
     ]
    }
   ],
   "source": [
    "#create citations across the board\n",
    "cite_keys[\"cites\"] = cite_keys[\"year:int\"].apply(lambda year: generate_citations(cite_keys, year))\n",
    "\n",
    "#create citations to journal articles, so that impact factor can calculated for more years\n",
    "cite_keys[\"cites_journal_specific\"] = cite_keys[\"year:int\"].apply(lambda year: generate_citations(article_keys, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>year:int</th>\n",
       "      <th>cites</th>\n",
       "      <th>cites_journal_specific</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>journals/wias/BouchetS13</td>\n",
       "      <td>2013</td>\n",
       "      <td>[journals/jmlr/GutmannH10, journals/jasis/Naya...</td>\n",
       "      <td>[journals/cce/SilvadM12, journals/cce/Rhinehar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>journals/wias/WalshLB12</td>\n",
       "      <td>2012</td>\n",
       "      <td>[journals/jasis/Oppenheim07, journals/procedia...</td>\n",
       "      <td>[journals/cce/GeS11, journals/jasis/Yakel05, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>journals/wias/McCareyCK08</td>\n",
       "      <td>2008</td>\n",
       "      <td>[journals/entcs/Ketema05, journals/cce/Mahdipo...</td>\n",
       "      <td>[journals/dss/LeeLY96, journals/dss/Fernandez-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>journals/wias/KulkarniV22</td>\n",
       "      <td>2022</td>\n",
       "      <td>[journals/cce/ChoiLR04, journals/jmlr/WangTMB0...</td>\n",
       "      <td>[journals/cce/AdiC13, journals/wias/CaoZL06, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>journals/wias/LiangZ19</td>\n",
       "      <td>2019</td>\n",
       "      <td>[journals/dss/GuoZK08, journals/dss/ChiuHLC12,...</td>\n",
       "      <td>[journals/cce/RahimiAPA15, journals/dss/Gregg0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     key:string  year:int  \\\n",
       "4628   journals/wias/BouchetS13      2013   \n",
       "4629    journals/wias/WalshLB12      2012   \n",
       "4630  journals/wias/McCareyCK08      2008   \n",
       "4631  journals/wias/KulkarniV22      2022   \n",
       "4632     journals/wias/LiangZ19      2019   \n",
       "\n",
       "                                                  cites  \\\n",
       "4628  [journals/jmlr/GutmannH10, journals/jasis/Naya...   \n",
       "4629  [journals/jasis/Oppenheim07, journals/procedia...   \n",
       "4630  [journals/entcs/Ketema05, journals/cce/Mahdipo...   \n",
       "4631  [journals/cce/ChoiLR04, journals/jmlr/WangTMB0...   \n",
       "4632  [journals/dss/GuoZK08, journals/dss/ChiuHLC12,...   \n",
       "\n",
       "                                 cites_journal_specific  \n",
       "4628  [journals/cce/SilvadM12, journals/cce/Rhinehar...  \n",
       "4629  [journals/cce/GeS11, journals/jasis/Yakel05, j...  \n",
       "4630  [journals/dss/LeeLY96, journals/dss/Fernandez-...  \n",
       "4631  [journals/cce/AdiC13, journals/wias/CaoZL06, j...  \n",
       "4632  [journals/cce/RahimiAPA15, journals/dss/Gregg0...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_keys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>year:int</th>\n",
       "      <th>cites</th>\n",
       "      <th>cites_journal_specific</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>journals/wias/BouchetS13</td>\n",
       "      <td>2013</td>\n",
       "      <td>journals/jmlr/GutmannH10|journals/jasis/Nayar0...</td>\n",
       "      <td>journals/cce/SilvadM12|journals/cce/RhinehartS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>journals/wias/WalshLB12</td>\n",
       "      <td>2012</td>\n",
       "      <td>journals/jasis/Oppenheim07|journals/procedia/B...</td>\n",
       "      <td>journals/cce/GeS11|journals/jasis/Yakel05|jour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4630</th>\n",
       "      <td>journals/wias/McCareyCK08</td>\n",
       "      <td>2008</td>\n",
       "      <td>journals/entcs/Ketema05|journals/cce/Mahdipoor...</td>\n",
       "      <td>journals/dss/LeeLY96|journals/dss/Fernandez-Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>journals/wias/KulkarniV22</td>\n",
       "      <td>2022</td>\n",
       "      <td>journals/cce/ChoiLR04|journals/jmlr/WangTMB09|...</td>\n",
       "      <td>journals/cce/AdiC13|journals/wias/CaoZL06|jour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>journals/wias/LiangZ19</td>\n",
       "      <td>2019</td>\n",
       "      <td>journals/dss/GuoZK08|journals/dss/ChiuHLC12|jo...</td>\n",
       "      <td>journals/cce/RahimiAPA15|journals/dss/Gregg09|...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     key:string  year:int  \\\n",
       "4628   journals/wias/BouchetS13      2013   \n",
       "4629    journals/wias/WalshLB12      2012   \n",
       "4630  journals/wias/McCareyCK08      2008   \n",
       "4631  journals/wias/KulkarniV22      2022   \n",
       "4632     journals/wias/LiangZ19      2019   \n",
       "\n",
       "                                                  cites  \\\n",
       "4628  journals/jmlr/GutmannH10|journals/jasis/Nayar0...   \n",
       "4629  journals/jasis/Oppenheim07|journals/procedia/B...   \n",
       "4630  journals/entcs/Ketema05|journals/cce/Mahdipoor...   \n",
       "4631  journals/cce/ChoiLR04|journals/jmlr/WangTMB09|...   \n",
       "4632  journals/dss/GuoZK08|journals/dss/ChiuHLC12|jo...   \n",
       "\n",
       "                                 cites_journal_specific  \n",
       "4628  journals/cce/SilvadM12|journals/cce/RhinehartS...  \n",
       "4629  journals/cce/GeS11|journals/jasis/Yakel05|jour...  \n",
       "4630  journals/dss/LeeLY96|journals/dss/Fernandez-Me...  \n",
       "4631  journals/cce/AdiC13|journals/wias/CaoZL06|jour...  \n",
       "4632  journals/cce/RahimiAPA15|journals/dss/Gregg09|...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list concatenation before writing list to file\n",
    "cite_keys[\"cites\"] = cite_keys[\"cites\"].apply(lambda x: \"|\".join(x))\n",
    "cite_keys[\"cites_journal_specific\"] = cite_keys[\"cites_journal_specific\"].apply(lambda x: \"|\".join(x))\n",
    "\n",
    "cite_keys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_keys.to_csv(\"data/citations.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create editor relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make authors a list\n",
    "articles[\"author_list\"] = articles[\"author:string[]\"].apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "#\n",
    "# expand authors to separate rows\n",
    "editors = articles.explode(\"author_list\")\n",
    "\n",
    "#group by researcher and journal\n",
    "editors = editors.groupby([\"author_list\", \"journal:string\"]).agg(publish_count=(\"author_list\",\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors = editors.sort_values(\"publish_count\", ascending=False)\n",
    "#get top 3 authors of each journal\n",
    "top_publishers = editors.groupby([\"journal:string\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>publish_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_list</th>\n",
       "      <th>journal:string</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ignacio E. Grossmann</th>\n",
       "      <th>Comput. Chem. Eng.</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike Thelwall</th>\n",
       "      <th>J. Assoc. Inf. Sci. Technol.</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loet Leydesdorff</th>\n",
       "      <th>J. Assoc. Inf. Sci. Technol.</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Efstratios N. Pistikopoulos</th>\n",
       "      <th>Comput. Chem. Eng.</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rafiqul Gani</th>\n",
       "      <th>Comput. Chem. Eng.</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lutz Bornmann</th>\n",
       "      <th>J. Assoc. Inf. Sci. Technol.</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hsinchun Chen</th>\n",
       "      <th>Decis. Support Syst.</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H. Raghav Rao</th>\n",
       "      <th>Decis. Support Syst.</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Selwyn Piramuthu</th>\n",
       "      <th>Decis. Support Syst.</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron D. Ames</th>\n",
       "      <th>IEEE Control. Syst. Lett.</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William B. Rouse</th>\n",
       "      <th>Inf. Knowl. Syst. Manag.</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuel Castro</th>\n",
       "      <th>Rev. Iberoam. de Tecnol. del Aprendiz.</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Andrew P. Sage</th>\n",
       "      <th>Inf. Knowl. Syst. Manag.</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Mulder</th>\n",
       "      <th>IEEE Trans. Hum. Mach. Syst.</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marinus Maria van Paassen</th>\n",
       "      <th>IEEE Trans. Hum. Mach. Syst.</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Majid Zamani 0001</th>\n",
       "      <th>IEEE Control. Syst. Lett.</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jacquelien M. A. Scherpen</th>\n",
       "      <th>IEEE Control. Syst. Lett.</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nong Ye</th>\n",
       "      <th>Inf. Knowl. Syst. Manag.</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fan R. K. Chung</th>\n",
       "      <th>Internet Math.</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pawel Pralat</th>\n",
       "      <th>Internet Math.</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Martín Llamas Nistal</th>\n",
       "      <th>Rev. Iberoam. de Tecnol. del Aprendiz.</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anthony Bonato</th>\n",
       "      <th>Internet Math.</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xabiel G. Pañeda</th>\n",
       "      <th>Rev. Iberoam. de Tecnol. del Aprendiz.</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Eitan Altman</th>\n",
       "      <th>Dyn. Games Appl.</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angela Carrillo Ramos</th>\n",
       "      <th>Int. J. Web Inf. Syst.</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    publish_count\n",
       "author_list                 journal:string                                       \n",
       "Ignacio E. Grossmann        Comput. Chem. Eng.                                153\n",
       "Mike Thelwall               J. Assoc. Inf. Sci. Technol.                       88\n",
       "Loet Leydesdorff            J. Assoc. Inf. Sci. Technol.                       83\n",
       "Efstratios N. Pistikopoulos Comput. Chem. Eng.                                 71\n",
       "Rafiqul Gani                Comput. Chem. Eng.                                 68\n",
       "Lutz Bornmann               J. Assoc. Inf. Sci. Technol.                       57\n",
       "Hsinchun Chen               Decis. Support Syst.                               49\n",
       "H. Raghav Rao               Decis. Support Syst.                               33\n",
       "Selwyn Piramuthu            Decis. Support Syst.                               31\n",
       "Aaron D. Ames               IEEE Control. Syst. Lett.                          26\n",
       "William B. Rouse            Inf. Knowl. Syst. Manag.                           22\n",
       "Manuel Castro               Rev. Iberoam. de Tecnol. del Aprendiz.             22\n",
       "Andrew P. Sage              Inf. Knowl. Syst. Manag.                           21\n",
       "Max Mulder                  IEEE Trans. Hum. Mach. Syst.                       19\n",
       "Marinus Maria van Paassen   IEEE Trans. Hum. Mach. Syst.                       15\n",
       "Majid Zamani 0001           IEEE Control. Syst. Lett.                          14\n",
       "Jacquelien M. A. Scherpen   IEEE Control. Syst. Lett.                          13\n",
       "Nong Ye                     Inf. Knowl. Syst. Manag.                           13\n",
       "Fan R. K. Chung             Internet Math.                                     13\n",
       "Pawel Pralat                Internet Math.                                     12\n",
       "Martín Llamas Nistal        Rev. Iberoam. de Tecnol. del Aprendiz.             12\n",
       "Anthony Bonato              Internet Math.                                     11\n",
       "Xabiel G. Pañeda            Rev. Iberoam. de Tecnol. del Aprendiz.             10\n",
       "Eitan Altman                Dyn. Games Appl.                                   10\n",
       "Angela Carrillo Ramos       Int. J. Web Inf. Syst.                              9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_publishers = top_publishers.rename(columns={\"author_list\": \"editor\", \"journal:string\": \"journal\"})\n",
    "top_publishers.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publishers.to_csv(\"data/editors.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Conference Chairpersons Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make authors a list\n",
    "inproceedings[\"author_list\"] = inproceedings[\"author:string[]\"].apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "#\n",
    "# expand authors to separate rows\n",
    "editors = inproceedings.explode(\"author_list\")\n",
    "\n",
    "#group by researcher and journal\n",
    "editors = editors.groupby([\"author_list\", \"crossref:string[]\"]).agg(publish_count=(\"author_list\",\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors = editors.sort_values(\"publish_count\", ascending=False)\n",
    "#get top 3 authors of each journal\n",
    "top_publishers = editors.groupby([\"crossref:string[]\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>publish_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_list</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mehmet Aksit</th>\n",
       "      <th>conf/abmb/2005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perla Velasco Elizondo</th>\n",
       "      <th>conf/abmb/2005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pablo Amaya</th>\n",
       "      <th>conf/abmb/2005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niels Joncheere</th>\n",
       "      <th>conf/abmb/2006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mehmet Aksit</th>\n",
       "      <th>conf/abmb/2006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathieu Braem</th>\n",
       "      <th>conf/abmb/2006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hartmut Ehrig</th>\n",
       "      <th>conf/accat/2007</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulrike Prange</th>\n",
       "      <th>conf/accat/2007</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leen Lambers</th>\n",
       "      <th>conf/accat/2007</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peter A. Flach</th>\n",
       "      <th>conf/acml/2010</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          publish_count\n",
       "author_list            crossref:string[]               \n",
       "Mehmet Aksit           conf/abmb/2005                 1\n",
       "Perla Velasco Elizondo conf/abmb/2005                 1\n",
       "Pablo Amaya            conf/abmb/2005                 1\n",
       "Niels Joncheere        conf/abmb/2006                 1\n",
       "Mehmet Aksit           conf/abmb/2006                 1\n",
       "Mathieu Braem          conf/abmb/2006                 1\n",
       "Hartmut Ehrig          conf/accat/2007                2\n",
       "Ulrike Prange          conf/accat/2007                3\n",
       "Leen Lambers           conf/accat/2007                1\n",
       "Peter A. Flach         conf/acml/2010                 1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_publishers = top_publishers.rename(columns={\"author_list\": \"chair\", \"crossref:string[]\": \"conference_edition\"})\n",
    "top_publishers.sort_values(\"crossref:string[]\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publishers.to_csv(\"data/conference_chairs.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create review information \n",
    "\n",
    "First the no of reviewers per journal/conference is determined. Usually this will be 3, however there is some variation introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal:string</th>\n",
       "      <th>no_reviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>Web Intell. Agent Syst.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>Web Intell.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>IEEE Trans. Hum. Mach. Syst.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>Comput. Chem. Eng.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11034</th>\n",
       "      <td>IEEE Control. Syst. Lett.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12786</th>\n",
       "      <td>Inf. Knowl. Syst. Manag.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>Internet Math.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13266</th>\n",
       "      <td>Int. J. Web Inf. Syst.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20840</th>\n",
       "      <td>Rev. Iberoam. de Tecnol. del Aprendiz.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21405</th>\n",
       "      <td>Dyn. Games Appl.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               journal:string  no_reviewers\n",
       "4628                  Web Intell. Agent Syst.             3\n",
       "4631                              Web Intell.             3\n",
       "5094             IEEE Trans. Hum. Mach. Syst.             3\n",
       "5889                       Comput. Chem. Eng.             1\n",
       "11034               IEEE Control. Syst. Lett.             3\n",
       "12786                Inf. Knowl. Syst. Manag.             3\n",
       "13011                          Internet Math.             3\n",
       "13266                  Int. J. Web Inf. Syst.             3\n",
       "20840  Rev. Iberoam. de Tecnol. del Aprendiz.             3\n",
       "21405                        Dyn. Games Appl.             3"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_list = articles[[\"journal:string\"]].drop_duplicates()\n",
    "conference_list = inproceedings[[\"booktitle:string\"]].drop_duplicates()\n",
    "\n",
    "conference_list.columns = journal_list.columns\n",
    "\n",
    "journal_conference_list = pd.concat([journal_list, conference_list])\n",
    "\n",
    "\n",
    "journal_conference_list[\"no_reviewers\"] = journal_conference_list[\"journal:string\"].apply(lambda x: random.randint(1,4) if random.randint(1,10) < 4 else 3)\n",
    "journal_conference_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviewer_count(journal_name):\n",
    "    return journal_conference_list[journal_conference_list[\"journal:string\"] == journal_name][\"no_reviewers\"].values[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the Reviews are created. for a paper the researchers participating in that review are determined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_short = articles[[\"key:string\",\"journal:string\", \"author_list\"]]\n",
    "ip_short = inproceedings[[\"key:string\",\"booktitle:string\", \"author_list\"]]\n",
    "\n",
    "ip_short.columns = art_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>journal:string</th>\n",
       "      <th>author_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Sven Lorenz, Toni Bollinger, Udo Pletat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Geoffrey Simmons, Kai-Uwe Carstensen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>[David W. Flater, Yelena Yesha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>journals/lncs/RollingerH91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Claus-Rainer Rollinger, Otthein Herzog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>journals/lncs/BhargavaJSD93</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>[Bharat K. Bhargava, Jagannathan Srinivasan, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>journals/lncs/DorreR91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Ingo Raasch, Jochen Dörre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>journals/lncs/Emde91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Werner Emde]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>journals/lncs/Ridoux94</td>\n",
       "      <td>Constraint Programming</td>\n",
       "      <td>[Olivier Ridoux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>journals/lncs/Blasius91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Karl-Hans Bläsius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>journals/lncs/LuckP91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Kai von Luck, Thomas Pirlein]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     key:string               journal:string  \\\n",
       "2   journals/lncs/BollingerLP91  Text Understanding in LILOG   \n",
       "3   journals/lncs/CarstensenS91  Text Understanding in LILOG   \n",
       "4       journals/lncs/FlaterY93    Advanced Database Systems   \n",
       "5    journals/lncs/RollingerH91  Text Understanding in LILOG   \n",
       "6   journals/lncs/BhargavaJSD93    Advanced Database Systems   \n",
       "7        journals/lncs/DorreR91  Text Understanding in LILOG   \n",
       "8          journals/lncs/Emde91  Text Understanding in LILOG   \n",
       "9        journals/lncs/Ridoux94       Constraint Programming   \n",
       "10      journals/lncs/Blasius91  Text Understanding in LILOG   \n",
       "11        journals/lncs/LuckP91  Text Understanding in LILOG   \n",
       "\n",
       "                                          author_list  \n",
       "2           [Sven Lorenz, Toni Bollinger, Udo Pletat]  \n",
       "3              [Geoffrey Simmons, Kai-Uwe Carstensen]  \n",
       "4                     [David W. Flater, Yelena Yesha]  \n",
       "5            [Claus-Rainer Rollinger, Otthein Herzog]  \n",
       "6   [Bharat K. Bhargava, Jagannathan Srinivasan, P...  \n",
       "7                         [Ingo Raasch, Jochen Dörre]  \n",
       "8                                       [Werner Emde]  \n",
       "9                                    [Olivier Ridoux]  \n",
       "10                                [Karl-Hans Bläsius]  \n",
       "11                     [Kai von Luck, Thomas Pirlein]  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_authors = pd.concat([ip_short, art_short])\n",
    "article_authors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliated_authors = article_authors.groupby('journal:string').agg({'author_list': \"sum\"})\n",
    "affiliated_authors[\"author_list\"] = affiliated_authors[\"author_list\"].apply(lambda x: set(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47149\n"
     ]
    }
   ],
   "source": [
    "affiliated_authors_dict = affiliated_authors.to_dict(\"index\")\n",
    "all_authors = set()\n",
    "\n",
    "for key, v in affiliated_authors_dict.items():\n",
    "    all_authors = all_authors.union(v[\"author_list\"])\n",
    "\n",
    "print(len(all_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Key:\n",
    "    PREVIOUS_KEY = \"Comput. Chem. Eng.\"\n",
    "\n",
    "def get_reviewers(key):\n",
    "    try:\n",
    "        author_sample = random.sample(affiliated_authors_dict[key][\"author_list\"], 5)\n",
    "        Key.PREVIOUS_KEY = key\n",
    "    except ValueError:\n",
    "        author_sample = random.sample(affiliated_authors_dict[Key.PREVIOUS_KEY][\"author_list\"], 5)\n",
    "    \n",
    "    return set(author_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\1130410631.py:6: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  author_sample = random.sample(affiliated_authors_dict[key][\"author_list\"], 5)\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\1130410631.py:9: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  author_sample = random.sample(affiliated_authors_dict[Key.PREVIOUS_KEY][\"author_list\"], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>journal:string</th>\n",
       "      <th>author_list</th>\n",
       "      <th>reviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Sven Lorenz, Toni Bollinger, Udo Pletat]</td>\n",
       "      <td>{Albert Maier, Peter Gerstl, Tibor Kiss, Gert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Geoffrey Simmons, Kai-Uwe Carstensen]</td>\n",
       "      <td>{Peter H. Schmitt, Birgit Wesche, Stefan Benzs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>[David W. Flater, Yelena Yesha]</td>\n",
       "      <td>{Ramez Elmasri, Shashi K. Gadia, Narain H. Geh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key:string               journal:string  \\\n",
       "2  journals/lncs/BollingerLP91  Text Understanding in LILOG   \n",
       "3  journals/lncs/CarstensenS91  Text Understanding in LILOG   \n",
       "4      journals/lncs/FlaterY93    Advanced Database Systems   \n",
       "\n",
       "                                 author_list  \\\n",
       "2  [Sven Lorenz, Toni Bollinger, Udo Pletat]   \n",
       "3     [Geoffrey Simmons, Kai-Uwe Carstensen]   \n",
       "4            [David W. Flater, Yelena Yesha]   \n",
       "\n",
       "                                           reviewers  \n",
       "2  {Albert Maier, Peter Gerstl, Tibor Kiss, Gert ...  \n",
       "3  {Peter H. Schmitt, Birgit Wesche, Stefan Benzs...  \n",
       "4  {Ramez Elmasri, Shashi K. Gadia, Narain H. Geh...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get sample of affiliated reviewers\n",
    "article_authors[\"reviewers\"] = article_authors[\"journal:string\"].apply(lambda x: get_reviewers(x))\n",
    "article_authors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove paper authors from reviewers\n",
    "article_authors[\"reviewers\"] = article_authors.apply(lambda row: row[\"reviewers\"].difference(set(row[\"author_list\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random reviewers where not enough\n",
    "def make_reviewers(current_reviewers:set, authors:set, journal:str):\n",
    "    no_reviewers = get_reviewer_count(journal)\n",
    "\n",
    "    while len(current_reviewers) < no_reviewers:\n",
    "        #add new sample\n",
    "        current_reviewers = current_reviewers.union(set(random.sample(all_authors, 1)))\n",
    "        #remove current authors\n",
    "        current_reviewers = current_reviewers.difference(authors)\n",
    "\n",
    "    if len(current_reviewers) >no_reviewers:\n",
    "        current_reviewers = set(random.sample(current_reviewers, no_reviewers))\n",
    "\n",
    "    return current_reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\2002427380.py:12: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  current_reviewers = set(random.sample(current_reviewers, no_reviewers))\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_3324\\2002427380.py:7: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  current_reviewers = current_reviewers.union(set(random.sample(all_authors, 1)))\n"
     ]
    }
   ],
   "source": [
    "article_authors[\"reviewers\"] = article_authors.apply(lambda row: make_reviewers(row[\"reviewers\"], set(row[\"author_list\"]), row[\"journal:string\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>reviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Roland Seiffert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Albert Maier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Peter Gerstl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Stefan Benzschawel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Simone Pribbenow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key:string           reviewers\n",
       "2  journals/lncs/BollingerLP91     Roland Seiffert\n",
       "2  journals/lncs/BollingerLP91        Albert Maier\n",
       "2  journals/lncs/BollingerLP91        Peter Gerstl\n",
       "3  journals/lncs/CarstensenS91  Stefan Benzschawel\n",
       "3  journals/lncs/CarstensenS91    Simone Pribbenow"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewers = article_authors[[\"key:string\", \"reviewers\"]].explode(\"reviewers\")\n",
    "reviewers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acceptance', 'conditional acceptance', 'outright rejection',\n",
       "       'conditional rejection'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate review text\n",
    "reviewers[\"review_text\"] = reviewers[\"reviewers\"].apply(lambda x: lipsum.generate_words(30))\n",
    "reviewers[\"suggested_decision\"] = reviewers[\"review_text\"].apply(lambda x: random.sample([\"acceptance\", \"conditional acceptance\", \"conditional rejection\", \"outright rejection\"],1)[0] if random.randint(1,10) < 2 else \"acceptance\")\n",
    "\n",
    "reviewers[\"suggested_decision\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers[\"supports_acceptance\"] = reviewers[\"suggested_decision\"].apply(lambda x : x in [\"acceptance\", \"conditional acceptance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75040"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptance_statistic = reviewers.groupby([\"key:string\"]).agg(acceptance_count=(\"supports_acceptance\",\"sum\"), no_reviewers=(\"reviewers\", \"count\"))\n",
    "acceptance_statistic[\"accepted\"] = acceptance_statistic[\"acceptance_count\"] > acceptance_statistic[\"no_reviewers\"]/2\n",
    "#acceptance_statistic[acceptance_statistic[\"accepted\"] == False]\n",
    "len(reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers.to_csv(\"data/reviewers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_list</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>organization_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>François Bouchet</td>\n",
       "      <td>University 25</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>Jean-Paul Sansonnet</td>\n",
       "      <td>Company 13</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>Alexander Borgida</td>\n",
       "      <td>Company 22</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>Michael L. Littman</td>\n",
       "      <td>Company 23</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4629</th>\n",
       "      <td>Thomas J. Walsh 0001</td>\n",
       "      <td>Company 10</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author_list    affiliation organization_type\n",
       "4628      François Bouchet  University 25        University\n",
       "4628   Jean-Paul Sansonnet     Company 13           Company\n",
       "4629     Alexander Borgida     Company 22           Company\n",
       "4629    Michael L. Littman     Company 23           Company\n",
       "4629  Thomas J. Walsh 0001     Company 10           Company"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations = pd.concat([articles[[\"author_list\"]], inproceedings[[\"author_list\"]]])\n",
    "affiliations = affiliations.explode(\"author_list\")\n",
    "affiliations[\"affiliation\"] = affiliations[\"author_list\"].apply(generate_affiliation)\n",
    "affiliations[\"organization_type\"] = affiliations[\"affiliation\"].apply(lambda x: x.split(\" \")[0])\n",
    "affiliations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliations.to_csv(\"data/affiliations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
