{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publication-Graph (Lab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to activate venv: venv\\Scripts\\activate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- created csv files with basic commands using the github recommended csv converter: XMLToCSV.py --annotate --neo4j data/dblp.xml data/dblp.dtd data/output.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import random\n",
    "import lipsum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "DATABASE_COMMUNITY_KEYWORDS = [\"data management\",\"indexing\", \"data modeling\", \"big data\", \"data processing\", \"data storage\",\"data querying\"]\n",
    "\n",
    "def create_keywords(title):\n",
    "    title = re.sub(r'[^\\w\\s]', \"\", title) #remove punctuation\n",
    "    word_tokens = word_tokenize(title)\n",
    "    keywords = set([w.lower() for w in word_tokens if not w.lower() in STOP_WORDS])\n",
    "\n",
    "    for kw in DATABASE_COMMUNITY_KEYWORDS:\n",
    "        if kw in title:\n",
    "            keywords.add(kw)\n",
    "\n",
    "    #add random database community kw to approx 30% of papers\n",
    "    if(random.randrange(0,10,1)<= 3):\n",
    "        keywords.add(random.sample(DATABASE_COMMUNITY_KEYWORDS,1)[0])\n",
    "\n",
    "    return \"|\".join(keywords)\n",
    "\n",
    "def trim_title(title):\n",
    "    if len(title)>300:\n",
    "        return title[:300]\n",
    "    \n",
    "    return title\n",
    "\n",
    "\n",
    "def generate_affiliation(row):\n",
    "    affil = {\n",
    "        1: \"Company\",\n",
    "        2: \"University\"\n",
    "    }\n",
    "\n",
    "    return f\"{affil.get(random.randint(1,2))} {random.randint(1,30)}\"\n",
    "\n",
    "def generate_publisher(publisher):\n",
    "    return f\"Publisher {random.randint(1,10)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_HEADERS_ARTICLE = [\n",
    "    \"article:ID\",\n",
    "    \"author:string[]\",\n",
    "    \"crossref:string\",#volume-key\n",
    "    \"editor:string[]\",\n",
    "    \"ee:string[]\",\n",
    "    \"journal:string\",#journal:name\n",
    "    \"key:string\", #paper:key\n",
    "    \"number:string\",#volume of the year\n",
    "    \"pages:string\",\n",
    "    \"title:string\", #paper:title\n",
    "    \"volume:string\",#consecutive issue number\n",
    "    \"year:int\", #volume:year,\n",
    "    \"publisher:string\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9978\n"
     ]
    }
   ],
   "source": [
    "header = \"\"\"article:ID;author:string[];author-aux:string;author-orcid:string[];booktitle:string;cdate:date;cdrom:string;cite:string[];cite-label:string[];crossref:string;editor:string[];editor-orcid:string[];ee:string[];ee-type:string[];i:string[];journal:string;key:string;mdate:date;month:string;note:string[];note-label:string;note-type:string[];number:string;pages:string;publisher:string;publnr:string;publtype:string;sub:string[];sup:string[];title:string;title-bibtex:string;tt:string[];url:string[];volume:string;year:int\"\"\".split(\";\")\n",
    "articles = pd.read_csv(\"data/output_article.csv\", nrows=10000, sep=\";\", names=header)\n",
    "articles = articles[KEEP_HEADERS_ARTICLE]\n",
    "\n",
    "#typing columns\n",
    "articles[\"crossref:string\"] = articles[\"crossref:string\"].astype(\"string\")\n",
    "articles[\"title:string\"] = articles[\"title:string\"].astype(\"string\")\n",
    "articles[\"author:string[]\"] = articles[\"author:string[]\"].astype(\"string\")\n",
    "pd.to_numeric(articles[\"number:string\"], errors=\"coerce\", downcast=\"integer\")\n",
    "pd.to_numeric(articles[\"year:int\"], downcast=\"integer\")\n",
    "\n",
    "#filter down to year > 1985\n",
    "articles = articles.dropna(subset=\"year:int\")\n",
    "articles = articles[articles[\"year:int\"] > 1985]\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doi_or_na(ee):\n",
    "    try:\n",
    "        doi = ee.split(\"|\")[0]\n",
    "        #returns the text if it is a doi, na otherwise\n",
    "        if(\"doi\" in ee):\n",
    "            return ee\n",
    "        \n",
    "    except:\n",
    "        print(\"no str found\")\n",
    "    \n",
    "    return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles[\"doi\"] = articles[\"ee:string[]\"].apply(lambda x: doi_or_na(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with no journal name\n",
    "articles = articles.dropna(subset=[\"journal:string\"])\n",
    "\n",
    "#drop articles without author\n",
    "articles = articles.dropna(subset=[\"author:string[]\"])\n",
    "\n",
    "#drop with no pages\n",
    "articles = articles.dropna(subset=[\"pages:string\"])\n",
    "\n",
    "#ensure title lenth\n",
    "articles = articles.dropna(subset=[\"title:string\"])\n",
    "articles[\"title:string\"] = articles[\"title:string\"].map(trim_title)\n",
    "\n",
    "#drop rows with missing year\n",
    "articles = articles.dropna(subset=[\"year:int\"])\n",
    "\n",
    "#assert volume 1 for missing volume number\n",
    "articles[\"number:string\"] = articles[\"number:string\"].fillna(1) #set volume number to 1 for missing ones\n",
    "\n",
    "#create volumekey\n",
    "articles[\"volume_key\"] = articles[\"journal:string\"] + articles[\"year:int\"].astype(\"string\") + articles[\"number:string\"].astype(\"string\")\n",
    "\n",
    "#fill missing crossref\n",
    "articles[\"crossref:string\"] = articles[\"crossref:string\"].fillna(articles[\"volume_key\"])\n",
    "\n",
    "#create corresponding_author\n",
    "articles[\"corresponding_author\"] = articles[\"author:string[]\"].apply(lambda x: x.split(\"|\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate keywords\n",
    "articles[\"keywords\"] = articles[\"title:string\"].map(create_keywords)\n",
    "articles[\"in_db_community\"] = articles[\"keywords\"].apply(lambda x: len(set(DATABASE_COMMUNITY_KEYWORDS).intersection(set(x.split(\"|\"))))>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate publishers\n",
    "articles[\"publisher\"] = articles[\"publisher:string\"].apply(generate_publisher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>crossref:string</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>journal:string</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:string</th>\n",
       "      <th>year:int</th>\n",
       "      <th>publisher:string</th>\n",
       "      <th>doi</th>\n",
       "      <th>volume_key</th>\n",
       "      <th>corresponding_author</th>\n",
       "      <th>keywords</th>\n",
       "      <th>in_db_community</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>577</td>\n",
       "      <td>Hugo Hellebrand|Markus Casper|Ralf Merz|Rita Ley</td>\n",
       "      <td>Hydrology and Earth System Sciences20111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.5194/hess-15-2947-2011</td>\n",
       "      <td>Hydrology and Earth System Sciences</td>\n",
       "      <td>persons/LeyCHM11</td>\n",
       "      <td>1</td>\n",
       "      <td>2947-2962</td>\n",
       "      <td>Catchment classification by runoff behaviour w...</td>\n",
       "      <td>15</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.5194/hess-15-2947-2011</td>\n",
       "      <td>Hydrology and Earth System Sciences20111</td>\n",
       "      <td>Hugo Hellebrand</td>\n",
       "      <td>selforganizing|maps|behaviour|classification|s...</td>\n",
       "      <td>False</td>\n",
       "      <td>Publisher 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>583</td>\n",
       "      <td>Markus Tresch</td>\n",
       "      <td>ETH Zurich, Department of Computer Science / T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3929/ethz-a-006651652</td>\n",
       "      <td>ETH Zurich, Department of Computer Science / T...</td>\n",
       "      <td>persons/Tresch96</td>\n",
       "      <td>1</td>\n",
       "      <td>1-27</td>\n",
       "      <td>Principles of Distributed Object Database Lang...</td>\n",
       "      <td>248</td>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.3929/ethz-a-006651652</td>\n",
       "      <td>ETH Zurich, Department of Computer Science / T...</td>\n",
       "      <td>Markus Tresch</td>\n",
       "      <td>languages|object|distributed|data management|d...</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>585</td>\n",
       "      <td>Andreas Rock|Gayane Grigoryan|Günther Heineman...</td>\n",
       "      <td>Hydrology and Earth System Sciences20121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.5194/hess-16-409-2012</td>\n",
       "      <td>Hydrology and Earth System Sciences</td>\n",
       "      <td>persons/CasperGGGHLR12</td>\n",
       "      <td>1</td>\n",
       "      <td>409-421</td>\n",
       "      <td>Analysis of projected hydrological behavior of...</td>\n",
       "      <td>16</td>\n",
       "      <td>2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.5194/hess-16-409-2012</td>\n",
       "      <td>Hydrology and Earth System Sciences20121</td>\n",
       "      <td>Andreas Rock</td>\n",
       "      <td>indices|data storage|behavior|analysis|hydrolo...</td>\n",
       "      <td>True</td>\n",
       "      <td>Publisher 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>28670</td>\n",
       "      <td>Sarah R. Davies</td>\n",
       "      <td>Sci. Eng. Ethics20194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/s11948-018-0064-y|http...</td>\n",
       "      <td>Sci. Eng. Ethics</td>\n",
       "      <td>journals/see/Davies19</td>\n",
       "      <td>4</td>\n",
       "      <td>1235-1253</td>\n",
       "      <td>An Ethics of the System: Talking to Scientists...</td>\n",
       "      <td>25</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/s11948-018-0064-y|http...</td>\n",
       "      <td>Sci. Eng. Ethics20194</td>\n",
       "      <td>Sarah R. Davies</td>\n",
       "      <td>integrity|scientists|research|talking|system|e...</td>\n",
       "      <td>False</td>\n",
       "      <td>Publisher 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>28671</td>\n",
       "      <td>Colleen Murphy|Paolo Gardoni</td>\n",
       "      <td>Sci. Eng. Ethics20081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/s11948-007-9031-8|http...</td>\n",
       "      <td>Sci. Eng. Ethics</td>\n",
       "      <td>journals/see/MurphyG08</td>\n",
       "      <td>1</td>\n",
       "      <td>77-92</td>\n",
       "      <td>The Acceptability and the Tolerability of Soci...</td>\n",
       "      <td>14</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/s11948-007-9031-8|http...</td>\n",
       "      <td>Sci. Eng. Ethics20081</td>\n",
       "      <td>Colleen Murphy</td>\n",
       "      <td>acceptability|tolerability|approach|risks|capa...</td>\n",
       "      <td>False</td>\n",
       "      <td>Publisher 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article:ID                                    author:string[]  \\\n",
       "558         577   Hugo Hellebrand|Markus Casper|Ralf Merz|Rita Ley   \n",
       "562         583                                      Markus Tresch   \n",
       "564         585  Andreas Rock|Gayane Grigoryan|Günther Heineman...   \n",
       "565       28670                                    Sarah R. Davies   \n",
       "566       28671                       Colleen Murphy|Paolo Gardoni   \n",
       "\n",
       "                                       crossref:string editor:string[]  \\\n",
       "558           Hydrology and Earth System Sciences20111             NaN   \n",
       "562  ETH Zurich, Department of Computer Science / T...             NaN   \n",
       "564           Hydrology and Earth System Sciences20121             NaN   \n",
       "565                              Sci. Eng. Ethics20194             NaN   \n",
       "566                              Sci. Eng. Ethics20081             NaN   \n",
       "\n",
       "                                           ee:string[]  \\\n",
       "558          https://doi.org/10.5194/hess-15-2947-2011   \n",
       "562           https://doi.org/10.3929/ethz-a-006651652   \n",
       "564           https://doi.org/10.5194/hess-16-409-2012   \n",
       "565  https://doi.org/10.1007/s11948-018-0064-y|http...   \n",
       "566  https://doi.org/10.1007/s11948-007-9031-8|http...   \n",
       "\n",
       "                                        journal:string  \\\n",
       "558                Hydrology and Earth System Sciences   \n",
       "562  ETH Zurich, Department of Computer Science / T...   \n",
       "564                Hydrology and Earth System Sciences   \n",
       "565                                   Sci. Eng. Ethics   \n",
       "566                                   Sci. Eng. Ethics   \n",
       "\n",
       "                 key:string number:string pages:string  \\\n",
       "558        persons/LeyCHM11             1    2947-2962   \n",
       "562        persons/Tresch96             1         1-27   \n",
       "564  persons/CasperGGGHLR12             1      409-421   \n",
       "565   journals/see/Davies19             4    1235-1253   \n",
       "566  journals/see/MurphyG08             1        77-92   \n",
       "\n",
       "                                          title:string volume:string  \\\n",
       "558  Catchment classification by runoff behaviour w...            15   \n",
       "562  Principles of Distributed Object Database Lang...           248   \n",
       "564  Analysis of projected hydrological behavior of...            16   \n",
       "565  An Ethics of the System: Talking to Scientists...            25   \n",
       "566  The Acceptability and the Tolerability of Soci...            14   \n",
       "\n",
       "     year:int publisher:string  \\\n",
       "558      2011              NaN   \n",
       "562      1996              NaN   \n",
       "564      2012              NaN   \n",
       "565      2019              NaN   \n",
       "566      2008              NaN   \n",
       "\n",
       "                                                   doi  \\\n",
       "558          https://doi.org/10.5194/hess-15-2947-2011   \n",
       "562           https://doi.org/10.3929/ethz-a-006651652   \n",
       "564           https://doi.org/10.5194/hess-16-409-2012   \n",
       "565  https://doi.org/10.1007/s11948-018-0064-y|http...   \n",
       "566  https://doi.org/10.1007/s11948-007-9031-8|http...   \n",
       "\n",
       "                                            volume_key corresponding_author  \\\n",
       "558           Hydrology and Earth System Sciences20111      Hugo Hellebrand   \n",
       "562  ETH Zurich, Department of Computer Science / T...        Markus Tresch   \n",
       "564           Hydrology and Earth System Sciences20121         Andreas Rock   \n",
       "565                              Sci. Eng. Ethics20194      Sarah R. Davies   \n",
       "566                              Sci. Eng. Ethics20081       Colleen Murphy   \n",
       "\n",
       "                                              keywords  in_db_community  \\\n",
       "558  selforganizing|maps|behaviour|classification|s...            False   \n",
       "562  languages|object|distributed|data management|d...             True   \n",
       "564  indices|data storage|behavior|analysis|hydrolo...             True   \n",
       "565  integrity|scientists|research|talking|system|e...            False   \n",
       "566  acceptability|tolerability|approach|risks|capa...            False   \n",
       "\n",
       "       publisher  \n",
       "558  Publisher 3  \n",
       "562  Publisher 7  \n",
       "564  Publisher 4  \n",
       "565  Publisher 3  \n",
       "566  Publisher 9  "
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()\n",
    "#print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9282\n"
     ]
    }
   ],
   "source": [
    "print(sum(articles[\"publisher:string\"].isna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.to_csv(\"data/articles_preprocessed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inproceedings preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_HEADER_INPROCEEDING = [\n",
    "    \"inproceedings:ID\",\n",
    "    \"author:string[]\",\n",
    "    \"booktitle:string\",#conference/forum title\n",
    "    \"crossref:string[]\",#proceeding key\n",
    "    \"editor:string[]\",\n",
    "    \"ee:string[]\",\n",
    "    \"key:string\",#inproceedings key\n",
    "    \"number:string\",\n",
    "    \"pages:string\",\n",
    "    \"title:string\",\n",
    "    \"volume:int\",\n",
    "    \"year:int\"#year_held\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9764\n"
     ]
    }
   ],
   "source": [
    "header = \"\"\"inproceedings:ID;author:string[];author-aux:string[];author-orcid:string[];booktitle:string;cdrom:string[];cite:string[];cite-label:string[];crossref:string[];editor:string[];editor-orcid:string[];ee:string[];ee-type:string[];i:string[];key:string;mdate:date;month:string;note:string;note-type:string;number:string;pages:string;publtype:string;sub:string[];sup:string[];title:string;title-bibtex:string;tt:string;url:string;volume:int;year:int\"\"\".split(\";\")\n",
    "inproceedings = pd.read_csv(\"data/output_inproceedings.csv\", nrows=10000, sep=\";\", names=header)\n",
    "inproceedings = inproceedings[KEEP_HEADER_INPROCEEDING]\n",
    "\n",
    "#typing columns\n",
    "inproceedings[\"crossref:string[]\"] = inproceedings[\"crossref:string[]\"].astype(\"string\")\n",
    "inproceedings[\"title:string\"] = inproceedings[\"title:string\"].astype(\"string\")\n",
    "pd.to_numeric(inproceedings[\"number:string\"], errors=\"coerce\", downcast=\"integer\")\n",
    "pd.to_numeric(inproceedings[\"year:int\"], downcast=\"integer\")\n",
    "inproceedings[\"author:string[]\"] = inproceedings[\"author:string[]\"].astype(\"string\")\n",
    "\n",
    "#only keep > 1985\n",
    "inproceedings = inproceedings.dropna(subset=\"year:int\")\n",
    "inproceedings = inproceedings[inproceedings[\"year:int\"] > 1985]\n",
    "print(len(inproceedings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inproceedings:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:int</th>\n",
       "      <th>year:int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555</td>\n",
       "      <td>Arnon Rosenthal</td>\n",
       "      <td>SWEE</td>\n",
       "      <td>conf/swee/1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.mitre.org/support/swee/rosenthal.html</td>\n",
       "      <td>www/org/mitre/future</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Future of Classic Data Administration: Obj...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159865</td>\n",
       "      <td>Sven Lorenz|Toni Bollinger|Udo Pletat</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_72</td>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402-427</td>\n",
       "      <td>The LILOG Inference Engine.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159866</td>\n",
       "      <td>Geoffrey Simmons|Kai-Uwe Carstensen</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_83</td>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632-644</td>\n",
       "      <td>Why a Hill Can't be a Valley: Representing Ges...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159867</td>\n",
       "      <td>David W. Flater|Yelena Yesha</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>journals/lncs/1993-759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_13</td>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259-276</td>\n",
       "      <td>Towards Flexible Distributed Information Retri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>159868</td>\n",
       "      <td>Claus-Rainer Rollinger|Otthein Herzog</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_46</td>\n",
       "      <td>journals/lncs/RollingerH91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-13</td>\n",
       "      <td>Introducing LILOG.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inproceedings:ID                        author:string[]  \\\n",
       "0               555                        Arnon Rosenthal   \n",
       "2            159865  Sven Lorenz|Toni Bollinger|Udo Pletat   \n",
       "3            159866    Geoffrey Simmons|Kai-Uwe Carstensen   \n",
       "4            159867           David W. Flater|Yelena Yesha   \n",
       "5            159868  Claus-Rainer Rollinger|Otthein Herzog   \n",
       "\n",
       "              booktitle:string       crossref:string[]  editor:string[]  \\\n",
       "0                         SWEE          conf/swee/1998              NaN   \n",
       "2  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "3  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "4    Advanced Database Systems  journals/lncs/1993-759              NaN   \n",
       "5  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "\n",
       "                                        ee:string[]  \\\n",
       "0  http://www.mitre.org/support/swee/rosenthal.html   \n",
       "2          https://doi.org/10.1007/3-540-54594-8_72   \n",
       "3          https://doi.org/10.1007/3-540-54594-8_83   \n",
       "4          https://doi.org/10.1007/3-540-57507-3_13   \n",
       "5          https://doi.org/10.1007/3-540-54594-8_46   \n",
       "\n",
       "                    key:string  number:string pages:string  \\\n",
       "0         www/org/mitre/future            NaN          NaN   \n",
       "2  journals/lncs/BollingerLP91            NaN      402-427   \n",
       "3  journals/lncs/CarstensenS91            NaN      632-644   \n",
       "4      journals/lncs/FlaterY93            NaN      259-276   \n",
       "5   journals/lncs/RollingerH91            NaN         3-13   \n",
       "\n",
       "                                        title:string  volume:int  year:int  \n",
       "0  The Future of Classic Data Administration: Obj...         NaN      1998  \n",
       "2                        The LILOG Inference Engine.         NaN      1991  \n",
       "3  Why a Hill Can't be a Valley: Representing Ges...         NaN      1991  \n",
       "4  Towards Flexible Distributed Information Retri...         NaN      1993  \n",
       "5                                 Introducing LILOG.         NaN      1991  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inproceedings.head()\n",
    "#print(inproceedings[\"booktitle:string\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no str found\n",
      "no str found\n",
      "no str found\n"
     ]
    }
   ],
   "source": [
    "#crossref is required to get the information from proceedings - thus crossref na are dropped\n",
    "inproceedings = inproceedings.dropna(subset=[\"crossref:string[]\"])\n",
    "\n",
    "#drop articles without author\n",
    "inproceedings = inproceedings.dropna(subset=[\"author:string[]\"])\n",
    "\n",
    "#create corresponding_author\n",
    "inproceedings[\"corresponding_author\"] = inproceedings[\"author:string[]\"].apply(lambda x: x.split(\"|\")[0])\n",
    "\n",
    "#we have enough elements so drop the ones without pages\n",
    "inproceedings = inproceedings.dropna(subset=[\"pages:string\"])\n",
    "\n",
    "#create doi\n",
    "inproceedings[\"doi\"] = inproceedings[\"ee:string[]\"].apply(doi_or_na)\n",
    "\n",
    "#ensure title lenth\n",
    "inproceedings = inproceedings.dropna(subset=[\"title:string\"])\n",
    "inproceedings[\"title:string\"] = inproceedings[\"title:string\"].map(trim_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9651\n"
     ]
    }
   ],
   "source": [
    "print(len(inproceedings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate keywords\n",
    "inproceedings[\"keywords\"] = inproceedings[\"title:string\"].map(create_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823\n",
      "<StringArray>\n",
      "[      'journals/lncs/1991-546',       'journals/lncs/1993-759',\n",
      "       'journals/lncs/1994-910',            'conf/nips/2008coa',\n",
      "            'conf/aistats/2012',            'conf/aistats/2010',\n",
      "            'conf/aistats/2011',            'conf/aistats/2007',\n",
      "               'conf/colt/2012',            'conf/aistats/2009',\n",
      " ...\n",
      "        'journals/corr/BeekL15',  'journals/corr/abs-1203-5423',\n",
      "     'journals/corr/DuboisMM17',  'journals/corr/abs-1108-4077',\n",
      "  'journals/corr/abs-1007-4993',       'journals/corr/Danvyd16',\n",
      "  'journals/corr/abs-1204-5796', 'journals/corr/abs-1805-04255',\n",
      " 'journals/corr/abs-1709-00049', 'journals/corr/abs-2107-01544']\n",
      "Length: 823, dtype: string\n"
     ]
    }
   ],
   "source": [
    "conference_crossrefs = inproceedings[\"crossref:string[]\"].unique()\n",
    "print(len(conference_crossrefs))\n",
    "print(conference_crossrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inproceedings:ID</th>\n",
       "      <th>author:string[]</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>pages:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:int</th>\n",
       "      <th>year:int</th>\n",
       "      <th>corresponding_author</th>\n",
       "      <th>doi</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159865</td>\n",
       "      <td>Sven Lorenz|Toni Bollinger|Udo Pletat</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_72</td>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402-427</td>\n",
       "      <td>The LILOG Inference Engine.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>Sven Lorenz</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_72</td>\n",
       "      <td>data modeling|engine|inference|lilog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159866</td>\n",
       "      <td>Geoffrey Simmons|Kai-Uwe Carstensen</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_83</td>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632-644</td>\n",
       "      <td>Why a Hill Can't be a Valley: Representing Ges...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>Geoffrey Simmons</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_83</td>\n",
       "      <td>representing|cant|properties|objects|object|va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>159867</td>\n",
       "      <td>David W. Flater|Yelena Yesha</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>journals/lncs/1993-759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_13</td>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259-276</td>\n",
       "      <td>Towards Flexible Distributed Information Retri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>David W. Flater</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_13</td>\n",
       "      <td>information|distributed|retrieval|towards|flex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>159868</td>\n",
       "      <td>Claus-Rainer Rollinger|Otthein Herzog</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>journals/lncs/1991-546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_46</td>\n",
       "      <td>journals/lncs/RollingerH91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3-13</td>\n",
       "      <td>Introducing LILOG.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991</td>\n",
       "      <td>Claus-Rainer Rollinger</td>\n",
       "      <td>https://doi.org/10.1007/3-540-54594-8_46</td>\n",
       "      <td>lilog|data management|introducing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>159869</td>\n",
       "      <td>Bharat K. Bhargava|Jagannathan Srinivasan|Pras...</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>journals/lncs/1993-759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_5</td>\n",
       "      <td>journals/lncs/BhargavaJSD93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87-103</td>\n",
       "      <td>Transition From A Relation To Object Model Imp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>Bharat K. Bhargava</td>\n",
       "      <td>https://doi.org/10.1007/3-540-57507-3_5</td>\n",
       "      <td>model|transition|implementation|object|relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inproceedings:ID                                    author:string[]  \\\n",
       "2            159865              Sven Lorenz|Toni Bollinger|Udo Pletat   \n",
       "3            159866                Geoffrey Simmons|Kai-Uwe Carstensen   \n",
       "4            159867                       David W. Flater|Yelena Yesha   \n",
       "5            159868              Claus-Rainer Rollinger|Otthein Herzog   \n",
       "6            159869  Bharat K. Bhargava|Jagannathan Srinivasan|Pras...   \n",
       "\n",
       "              booktitle:string       crossref:string[]  editor:string[]  \\\n",
       "2  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "3  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "4    Advanced Database Systems  journals/lncs/1993-759              NaN   \n",
       "5  Text Understanding in LILOG  journals/lncs/1991-546              NaN   \n",
       "6    Advanced Database Systems  journals/lncs/1993-759              NaN   \n",
       "\n",
       "                                ee:string[]                   key:string  \\\n",
       "2  https://doi.org/10.1007/3-540-54594-8_72  journals/lncs/BollingerLP91   \n",
       "3  https://doi.org/10.1007/3-540-54594-8_83  journals/lncs/CarstensenS91   \n",
       "4  https://doi.org/10.1007/3-540-57507-3_13      journals/lncs/FlaterY93   \n",
       "5  https://doi.org/10.1007/3-540-54594-8_46   journals/lncs/RollingerH91   \n",
       "6   https://doi.org/10.1007/3-540-57507-3_5  journals/lncs/BhargavaJSD93   \n",
       "\n",
       "   number:string pages:string  \\\n",
       "2            NaN      402-427   \n",
       "3            NaN      632-644   \n",
       "4            NaN      259-276   \n",
       "5            NaN         3-13   \n",
       "6            NaN       87-103   \n",
       "\n",
       "                                        title:string  volume:int  year:int  \\\n",
       "2                        The LILOG Inference Engine.         NaN      1991   \n",
       "3  Why a Hill Can't be a Valley: Representing Ges...         NaN      1991   \n",
       "4  Towards Flexible Distributed Information Retri...         NaN      1993   \n",
       "5                                 Introducing LILOG.         NaN      1991   \n",
       "6  Transition From A Relation To Object Model Imp...         NaN      1993   \n",
       "\n",
       "     corresponding_author                                       doi  \\\n",
       "2             Sven Lorenz  https://doi.org/10.1007/3-540-54594-8_72   \n",
       "3        Geoffrey Simmons  https://doi.org/10.1007/3-540-54594-8_83   \n",
       "4         David W. Flater  https://doi.org/10.1007/3-540-57507-3_13   \n",
       "5  Claus-Rainer Rollinger  https://doi.org/10.1007/3-540-54594-8_46   \n",
       "6      Bharat K. Bhargava   https://doi.org/10.1007/3-540-57507-3_5   \n",
       "\n",
       "                                            keywords  \n",
       "2               data modeling|engine|inference|lilog  \n",
       "3  representing|cant|properties|objects|object|va...  \n",
       "4  information|distributed|retrieval|towards|flex...  \n",
       "5                  lilog|data management|introducing  \n",
       "6    model|transition|implementation|object|relation  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inproceedings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "inproceedings.to_csv(\"data/inproceedings_preprocessed.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess proceedings csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_HEADER_PROCEEDING = [\n",
    "    \"proceedings:ID\",\n",
    "    \"booktitle:string\",\n",
    "    \"editor:string[]\",\n",
    "    \"ee:string[]\",\n",
    "    \"key:string\",\n",
    "    \"number:string\",\n",
    "    \"title:string\",\n",
    "    \"volume:string\",\n",
    "    \"year:int\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_53740\\3556115800.py:2: DtypeWarning: Columns (1,2,4,5,10,12,13,18,19,22,23,26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  proceedings = pd.read_csv(\"data/output_proceedings.csv\", nrows=100000, sep=\";\", names=header)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        1999\n",
       "1        2015\n",
       "2        2013\n",
       "3        2014\n",
       "4        2019\n",
       "         ... \n",
       "53876    2013\n",
       "53877    2007\n",
       "53878    1999\n",
       "53879    2017\n",
       "53880    2010\n",
       "Name: year:int, Length: 53881, dtype: int16"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = \"\"\"proceedings:ID;address:string;author:string[];booktitle:string;cite:string[];cite-label:string[];editor:string[];editor-orcid:string[];ee:string[];ee-type:string[];i:string;isbn:string[];isbn-type:string[];journal:string;key:string;mdate:date;note:string[];note-type:string;number:string;pages:string;publisher:string[];publisher-href:string;publtype:string;school:string;series:string[];series-href:string[];sub:string;sup:string[];title:string;url:string[];volume:string;year:int\"\"\".split(\";\")\n",
    "proceedings = pd.read_csv(\"data/output_proceedings.csv\", nrows=100000, sep=\";\", names=header)\n",
    "proceedings = proceedings[KEEP_HEADER_PROCEEDING]\n",
    "\n",
    "#typing columns\n",
    "proceedings[\"title:string\"] = proceedings[\"title:string\"].astype(\"string\")\n",
    "pd.to_numeric(proceedings[\"number:string\"], errors=\"coerce\", downcast=\"integer\")\n",
    "pd.to_numeric(proceedings[\"year:int\"], downcast=\"integer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proceedings:ID</th>\n",
       "      <th>booktitle:string</th>\n",
       "      <th>editor:string[]</th>\n",
       "      <th>ee:string[]</th>\n",
       "      <th>key:string</th>\n",
       "      <th>number:string</th>\n",
       "      <th>title:string</th>\n",
       "      <th>volume:string</th>\n",
       "      <th>year:int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461</td>\n",
       "      <td>MMB (Kurzvorträge)</td>\n",
       "      <td>Dieter Baum|Norbert Th. Müller|Richard Rödler</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tr/trier/MI99-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MMB '99, Messung, Modellierung und Bewertung v...</td>\n",
       "      <td>99-16</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amir Hossein Alavi|Amir Hossein Gandomi|Conor ...</td>\n",
       "      <td>https://doi.org/10.1007/978-3-319-20883-1</td>\n",
       "      <td>reference/genetic/2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handbook of Genetic Programming Applications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ankur Agarwal|Borko Furht</td>\n",
       "      <td>https://doi.org/10.1007/978-1-4614-8495-0</td>\n",
       "      <td>reference/med/2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handbook of Medical and Healthcare Technologies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103589</td>\n",
       "      <td>Trans. Computational Collective Intelligence</td>\n",
       "      <td>Ngoc Thanh Nguyen</td>\n",
       "      <td>https://doi.org/10.1007/978-3-662-44509-9</td>\n",
       "      <td>journals/tcci/2014-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transactions on Computational Collective Intel...</td>\n",
       "      <td>8615</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marcin Hernes|Ngoc Thanh Nguyen|Ryszard Kowalczyk</td>\n",
       "      <td>https://doi.org/10.1007/978-3-662-58611-2</td>\n",
       "      <td>journals/tcci/2019-32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Transactions on Computational Collective Intel...</td>\n",
       "      <td>11370</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proceedings:ID                              booktitle:string  \\\n",
       "0             461                            MMB (Kurzvorträge)   \n",
       "1            2240                                           NaN   \n",
       "2           13516                                           NaN   \n",
       "3          103589  Trans. Computational Collective Intelligence   \n",
       "4          103594                                           NaN   \n",
       "\n",
       "                                     editor:string[]  \\\n",
       "0      Dieter Baum|Norbert Th. Müller|Richard Rödler   \n",
       "1  Amir Hossein Alavi|Amir Hossein Gandomi|Conor ...   \n",
       "2                          Ankur Agarwal|Borko Furht   \n",
       "3                                  Ngoc Thanh Nguyen   \n",
       "4  Marcin Hernes|Ngoc Thanh Nguyen|Ryszard Kowalczyk   \n",
       "\n",
       "                                 ee:string[]              key:string  \\\n",
       "0                                        NaN        tr/trier/MI99-17   \n",
       "1  https://doi.org/10.1007/978-3-319-20883-1  reference/genetic/2015   \n",
       "2  https://doi.org/10.1007/978-1-4614-8495-0      reference/med/2013   \n",
       "3  https://doi.org/10.1007/978-3-662-44509-9   journals/tcci/2014-14   \n",
       "4  https://doi.org/10.1007/978-3-662-58611-2   journals/tcci/2019-32   \n",
       "\n",
       "  number:string                                       title:string  \\\n",
       "0           NaN  MMB '99, Messung, Modellierung und Bewertung v...   \n",
       "1           NaN       Handbook of Genetic Programming Applications   \n",
       "2           NaN    Handbook of Medical and Healthcare Technologies   \n",
       "3           NaN  Transactions on Computational Collective Intel...   \n",
       "4           NaN  Transactions on Computational Collective Intel...   \n",
       "\n",
       "  volume:string  year:int  \n",
       "0         99-16      1999  \n",
       "1           NaN      2015  \n",
       "2           NaN      2013  \n",
       "3          8615      2014  \n",
       "4         11370      2019  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proceedings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop where title not present\n",
    "proceedings = proceedings.dropna(subset=[\"title:string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823\n"
     ]
    }
   ],
   "source": [
    "#filter proceedings down to relevant subset from selected papers\n",
    "proceedings[\"in_selected_ip_subset\"] = proceedings[\"key:string\"].apply(lambda x: True if x in conference_crossrefs else pd.NA)\n",
    "proceedings = proceedings.dropna(subset=[\"in_selected_ip_subset\"])\n",
    "print(sum(proceedings[\"in_selected_ip_subset\"]))\n",
    "\n",
    "#create doi\n",
    "proceedings[\"doi\"] = proceedings[\"ee:string[]\"].apply(doi_or_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get edition where possible\n",
    "def get_edition(volume):\n",
    "    try:\n",
    "        return volume.split(\"-\")[1]\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "proceedings[\"edition\"] = proceedings[\"volume:string\"].map(get_edition)\n",
    "proceedings[\"edition\"] = proceedings[\"edition\"].fillna(proceedings[\"volume:string\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "proceedings.to_csv(\"data/proceedings_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       key:string  year:int\n",
      "558              persons/LeyCHM11      2011\n",
      "562              persons/Tresch96      1996\n",
      "564        persons/CasperGGGHLR12      2012\n",
      "565         journals/see/Davies19      2019\n",
      "566        journals/see/MurphyG08      2008\n",
      "...                           ...       ...\n",
      "9995        journals/cce/VidalM15      2015\n",
      "9996          journals/cce/LiuK08      2008\n",
      "9997        journals/cce/ApioBT18      2018\n",
      "9998  journals/cce/BattistiCMMM20      2020\n",
      "9999  journals/cce/RebughiniCDM17      2017\n",
      "\n",
      "[9282 rows x 2 columns]\n",
      "                        key:string  year:int\n",
      "2      journals/lncs/BollingerLP91      1991\n",
      "3      journals/lncs/CarstensenS91      1991\n",
      "4          journals/lncs/FlaterY93      1993\n",
      "5       journals/lncs/RollingerH91      1991\n",
      "6      journals/lncs/BhargavaJSD93      1993\n",
      "...                            ...       ...\n",
      "9995       journals/corr/BlancoM15      2015\n",
      "9996  journals/corr/abs-2109-08303      2021\n",
      "9997   journals/corr/abs-1108-1865      2011\n",
      "9998        journals/corr/DavisK14      2014\n",
      "9999  journals/corr/abs-2107-06820      2021\n",
      "\n",
      "[9651 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#paper keys and years from articles\n",
    "article_keys = articles[[\"key:string\",\"year:int\"]]\n",
    "print(article_keys)\n",
    "\n",
    "ip_keys = inproceedings[[\"key:string\",\"year:int\"]]\n",
    "print(ip_keys)\n",
    "\n",
    "## union both\n",
    "cite_keys = pd.concat([article_keys, ip_keys])\n",
    "#cite_keys[\"year:int\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_citations(df, year):\n",
    "    no_citations = random.randint(5,15)\n",
    "\n",
    "    df = df[df[\"year:int\"] < year]\n",
    "\n",
    "    try:\n",
    "        citation_keys = df[\"key:string\"].sample(no_citations, random_state=42).tolist()\n",
    "    except ValueError:\n",
    "        print(f\"could not make sample for year {year}\")\n",
    "        citation_keys = []\n",
    "\n",
    "    return citation_keys    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n",
      "could not make sample for year 1986\n"
     ]
    }
   ],
   "source": [
    "cite_keys[\"cites\"] = cite_keys[\"year:int\"].apply(lambda year: generate_citations(cite_keys, year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>year:int</th>\n",
       "      <th>cites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>persons/LeyCHM11</td>\n",
       "      <td>2011</td>\n",
       "      <td>[journals/entcs/KerjeanKST06, journals/jet/Ehl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>persons/Tresch96</td>\n",
       "      <td>1996</td>\n",
       "      <td>[journals/oopsm/MalenfantLV91, journals/lncs/K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>persons/CasperGGGHLR12</td>\n",
       "      <td>2012</td>\n",
       "      <td>[journals/entcs/RebernakMHP06, journals/proced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>journals/see/Davies19</td>\n",
       "      <td>2019</td>\n",
       "      <td>[journals/entcs/Merro07, journals/jet/Dokumaci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>journals/see/MurphyG08</td>\n",
       "      <td>2008</td>\n",
       "      <td>[journals/entcs/RaymondRJ08, journals/sigcse/W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 key:string  year:int  \\\n",
       "558        persons/LeyCHM11      2011   \n",
       "562        persons/Tresch96      1996   \n",
       "564  persons/CasperGGGHLR12      2012   \n",
       "565   journals/see/Davies19      2019   \n",
       "566  journals/see/MurphyG08      2008   \n",
       "\n",
       "                                                 cites  \n",
       "558  [journals/entcs/KerjeanKST06, journals/jet/Ehl...  \n",
       "562  [journals/oopsm/MalenfantLV91, journals/lncs/K...  \n",
       "564  [journals/entcs/RebernakMHP06, journals/proced...  \n",
       "565  [journals/entcs/Merro07, journals/jet/Dokumaci...  \n",
       "566  [journals/entcs/RaymondRJ08, journals/sigcse/W...  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_keys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>year:int</th>\n",
       "      <th>cites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>persons/LeyCHM11</td>\n",
       "      <td>2011</td>\n",
       "      <td>journals/entcs/KerjeanKST06|journals/jet/Ehler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>persons/Tresch96</td>\n",
       "      <td>1996</td>\n",
       "      <td>journals/oopsm/MalenfantLV91|journals/lncs/Khe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>persons/CasperGGGHLR12</td>\n",
       "      <td>2012</td>\n",
       "      <td>journals/entcs/RebernakMHP06|journals/procedia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>journals/see/Davies19</td>\n",
       "      <td>2019</td>\n",
       "      <td>journals/entcs/Merro07|journals/jet/DokumaciS1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>journals/see/MurphyG08</td>\n",
       "      <td>2008</td>\n",
       "      <td>journals/entcs/RaymondRJ08|journals/sigcse/Wal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 key:string  year:int  \\\n",
       "558        persons/LeyCHM11      2011   \n",
       "562        persons/Tresch96      1996   \n",
       "564  persons/CasperGGGHLR12      2012   \n",
       "565   journals/see/Davies19      2019   \n",
       "566  journals/see/MurphyG08      2008   \n",
       "\n",
       "                                                 cites  \n",
       "558  journals/entcs/KerjeanKST06|journals/jet/Ehler...  \n",
       "562  journals/oopsm/MalenfantLV91|journals/lncs/Khe...  \n",
       "564  journals/entcs/RebernakMHP06|journals/procedia...  \n",
       "565  journals/entcs/Merro07|journals/jet/DokumaciS1...  \n",
       "566  journals/entcs/RaymondRJ08|journals/sigcse/Wal...  "
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cite_keys[\"cites\"] = cite_keys[\"cites\"].apply(lambda x: \"|\".join(x))\n",
    "cite_keys.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "cite_keys.to_csv(\"data/citations.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create editor and chairperson relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make authors a list\n",
    "articles[\"author_list\"] = articles[\"author:string[]\"].apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "#\n",
    "# expand authors to separate rows\n",
    "editors = articles.explode(\"author_list\")\n",
    "\n",
    "#group by researcher and journal\n",
    "editors = editors.groupby([\"author_list\", \"journal:string\"]).agg(publish_count=(\"author_list\",\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors = editors.sort_values(\"publish_count\", ascending=False)\n",
    "#get top 3 authors of each journal\n",
    "top_publishers = editors.groupby([\"journal:string\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>publish_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_list</th>\n",
       "      <th>journal:string</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ignacio E. Grossmann</th>\n",
       "      <th>Comput. Chem. Eng.</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rafiqul Gani</th>\n",
       "      <th>Comput. Chem. Eng.</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Efstratios N. Pistikopoulos</th>\n",
       "      <th>Comput. Chem. Eng.</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max Mulder</th>\n",
       "      <th>IEEE Trans. Hum. Mach. Syst.</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luciano Floridi</th>\n",
       "      <th>Sci. Eng. Ethics</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael D. Mumford</th>\n",
       "      <th>Sci. Eng. Ethics</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drew Fudenberg</th>\n",
       "      <th>J. Econ. Theory</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stephanie J. Bird</th>\n",
       "      <th>Sci. Eng. Ethics</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massimo Marinacci</th>\n",
       "      <th>J. Econ. Theory</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marinus Maria van Paassen</th>\n",
       "      <th>IEEE Trans. Hum. Mach. Syst.</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Randall Wright</th>\n",
       "      <th>J. Econ. Theory</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ellen J. Bass</th>\n",
       "      <th>IEEE Trans. Hum. Mach. Syst.</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jan Treur</th>\n",
       "      <th>Web Intell. Agent Syst.</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaohui Tao</th>\n",
       "      <th>Web Intell.</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li Liu 0001</th>\n",
       "      <th>Web Intell.</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tibor Bosse</th>\n",
       "      <th>Web Intell. Agent Syst.</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Domenico Ursino</th>\n",
       "      <th>Web Intell. Agent Syst.</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yuefeng Li</th>\n",
       "      <th>Web Intell.</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markus Casper</th>\n",
       "      <th>Hydrology and Earth System Sciences</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rita Ley</th>\n",
       "      <th>Hydrology and Earth System Sciences</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oliver Gronz</th>\n",
       "      <th>Hydrology and Earth System Sciences</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markus Tresch</th>\n",
       "      <th>ETH Zurich, Department of Computer Science / Technical Report</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                publish_count\n",
       "author_list                 journal:string                                                   \n",
       "Ignacio E. Grossmann        Comput. Chem. Eng.                                            119\n",
       "Rafiqul Gani                Comput. Chem. Eng.                                             59\n",
       "Efstratios N. Pistikopoulos Comput. Chem. Eng.                                             53\n",
       "Max Mulder                  IEEE Trans. Hum. Mach. Syst.                                   19\n",
       "Luciano Floridi             Sci. Eng. Ethics                                               16\n",
       "Michael D. Mumford          Sci. Eng. Ethics                                               16\n",
       "Drew Fudenberg              J. Econ. Theory                                                15\n",
       "Stephanie J. Bird           Sci. Eng. Ethics                                               15\n",
       "Massimo Marinacci           J. Econ. Theory                                                15\n",
       "Marinus Maria van Paassen   IEEE Trans. Hum. Mach. Syst.                                   15\n",
       "Randall Wright              J. Econ. Theory                                                14\n",
       "Ellen J. Bass               IEEE Trans. Hum. Mach. Syst.                                    8\n",
       "Jan Treur                   Web Intell. Agent Syst.                                         7\n",
       "Xiaohui Tao                 Web Intell.                                                     7\n",
       "Li Liu 0001                 Web Intell.                                                     6\n",
       "Tibor Bosse                 Web Intell. Agent Syst.                                         5\n",
       "Domenico Ursino             Web Intell. Agent Syst.                                         5\n",
       "Yuefeng Li                  Web Intell.                                                     4\n",
       "Markus Casper               Hydrology and Earth System Sciences                             2\n",
       "Rita Ley                    Hydrology and Earth System Sciences                             2\n",
       "Oliver Gronz                Hydrology and Earth System Sciences                             1\n",
       "Markus Tresch               ETH Zurich, Department of Computer Science / Te...              1"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_publishers = top_publishers.rename(columns={\"author_list\": \"editor\", \"journal:string\": \"journal\"})\n",
    "top_publishers.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publishers.to_csv(\"data/editors.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conference Chairpersons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make authors a list\n",
    "inproceedings[\"author_list\"] = inproceedings[\"author:string[]\"].apply(lambda x: x.split(\"|\"))\n",
    "\n",
    "#\n",
    "# expand authors to separate rows\n",
    "editors = inproceedings.explode(\"author_list\")\n",
    "\n",
    "#group by researcher and journal\n",
    "editors = editors.groupby([\"author_list\", \"crossref:string[]\"]).agg(publish_count=(\"author_list\",\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "editors = editors.sort_values(\"publish_count\", ascending=False)\n",
    "#get top 3 authors of each journal\n",
    "top_publishers = editors.groupby([\"crossref:string[]\"]).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>publish_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_list</th>\n",
       "      <th>crossref:string[]</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pablo Amaya</th>\n",
       "      <th>conf/abmb/2005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mehmet Aksit</th>\n",
       "      <th>conf/abmb/2005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perla Velasco Elizondo</th>\n",
       "      <th>conf/abmb/2005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Niels Joncheere</th>\n",
       "      <th>conf/abmb/2006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathieu Braem</th>\n",
       "      <th>conf/abmb/2006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mehmet Aksit</th>\n",
       "      <th>conf/abmb/2006</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hartmut Ehrig</th>\n",
       "      <th>conf/accat/2007</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leen Lambers</th>\n",
       "      <th>conf/accat/2007</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ulrike Prange</th>\n",
       "      <th>conf/accat/2007</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mostafa Ajallooeian</th>\n",
       "      <th>conf/acml/2010</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          publish_count\n",
       "author_list            crossref:string[]               \n",
       "Pablo Amaya            conf/abmb/2005                 1\n",
       "Mehmet Aksit           conf/abmb/2005                 1\n",
       "Perla Velasco Elizondo conf/abmb/2005                 1\n",
       "Niels Joncheere        conf/abmb/2006                 1\n",
       "Mathieu Braem          conf/abmb/2006                 1\n",
       "Mehmet Aksit           conf/abmb/2006                 1\n",
       "Hartmut Ehrig          conf/accat/2007                2\n",
       "Leen Lambers           conf/accat/2007                1\n",
       "Ulrike Prange          conf/accat/2007                3\n",
       "Mostafa Ajallooeian    conf/acml/2010                 1"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_publishers = top_publishers.rename(columns={\"author_list\": \"chair\", \"crossref:string[]\": \"conference_edition\"})\n",
    "top_publishers.sort_values(\"crossref:string[]\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publishers.to_csv(\"data/conference_chairs.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no of reviewers per journal/conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>journal:string</th>\n",
       "      <th>no_reviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Hydrology and Earth System Sciences</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>ETH Zurich, Department of Computer Science / T...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Sci. Eng. Ethics</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>J. Econ. Theory</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>Web Intell. Agent Syst.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4631</th>\n",
       "      <td>Web Intell.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5094</th>\n",
       "      <td>IEEE Trans. Hum. Mach. Syst.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>Comput. Chem. Eng.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         journal:string  no_reviewers\n",
       "558                 Hydrology and Earth System Sciences             3\n",
       "562   ETH Zurich, Department of Computer Science / T...             3\n",
       "565                                    Sci. Eng. Ethics             3\n",
       "1960                                    J. Econ. Theory             3\n",
       "4628                            Web Intell. Agent Syst.             2\n",
       "4631                                        Web Intell.             4\n",
       "5094                       IEEE Trans. Hum. Mach. Syst.             3\n",
       "5889                                 Comput. Chem. Eng.             3\n",
       "2                           Text Understanding in LILOG             3\n",
       "4                             Advanced Database Systems             3"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_list = articles[[\"journal:string\"]].drop_duplicates()\n",
    "conference_list = inproceedings[[\"booktitle:string\"]].drop_duplicates()\n",
    "\n",
    "conference_list.columns = journal_list.columns\n",
    "\n",
    "journal_conference_list = pd.concat([journal_list, conference_list])\n",
    "\n",
    "\n",
    "journal_conference_list[\"no_reviewers\"] = journal_conference_list[\"journal:string\"].apply(lambda x: random.randint(1,4) if random.randint(1,10) < 4 else 3)\n",
    "journal_conference_list.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviewer_count(journal_name):\n",
    "    return journal_conference_list[journal_conference_list[\"journal:string\"] == journal_name][\"no_reviewers\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "art_short = articles[[\"key:string\",\"journal:string\", \"author_list\"]]\n",
    "ip_short = inproceedings[[\"key:string\",\"booktitle:string\", \"author_list\"]]\n",
    "\n",
    "ip_short.columns = art_short.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>journal:string</th>\n",
       "      <th>author_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Sven Lorenz, Toni Bollinger, Udo Pletat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Geoffrey Simmons, Kai-Uwe Carstensen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>[David W. Flater, Yelena Yesha]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>journals/lncs/RollingerH91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Claus-Rainer Rollinger, Otthein Herzog]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>journals/lncs/BhargavaJSD93</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>[Bharat K. Bhargava, Jagannathan Srinivasan, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>journals/lncs/DorreR91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Ingo Raasch, Jochen Dörre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>journals/lncs/Emde91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Werner Emde]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>journals/lncs/Ridoux94</td>\n",
       "      <td>Constraint Programming</td>\n",
       "      <td>[Olivier Ridoux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>journals/lncs/Blasius91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Karl-Hans Bläsius]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>journals/lncs/LuckP91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Kai von Luck, Thomas Pirlein]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     key:string               journal:string  \\\n",
       "2   journals/lncs/BollingerLP91  Text Understanding in LILOG   \n",
       "3   journals/lncs/CarstensenS91  Text Understanding in LILOG   \n",
       "4       journals/lncs/FlaterY93    Advanced Database Systems   \n",
       "5    journals/lncs/RollingerH91  Text Understanding in LILOG   \n",
       "6   journals/lncs/BhargavaJSD93    Advanced Database Systems   \n",
       "7        journals/lncs/DorreR91  Text Understanding in LILOG   \n",
       "8          journals/lncs/Emde91  Text Understanding in LILOG   \n",
       "9        journals/lncs/Ridoux94       Constraint Programming   \n",
       "10      journals/lncs/Blasius91  Text Understanding in LILOG   \n",
       "11        journals/lncs/LuckP91  Text Understanding in LILOG   \n",
       "\n",
       "                                          author_list  \n",
       "2           [Sven Lorenz, Toni Bollinger, Udo Pletat]  \n",
       "3              [Geoffrey Simmons, Kai-Uwe Carstensen]  \n",
       "4                     [David W. Flater, Yelena Yesha]  \n",
       "5            [Claus-Rainer Rollinger, Otthein Herzog]  \n",
       "6   [Bharat K. Bhargava, Jagannathan Srinivasan, P...  \n",
       "7                         [Ingo Raasch, Jochen Dörre]  \n",
       "8                                       [Werner Emde]  \n",
       "9                                    [Olivier Ridoux]  \n",
       "10                                [Karl-Hans Bläsius]  \n",
       "11                     [Kai von Luck, Thomas Pirlein]  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_authors = pd.concat([ip_short, art_short])\n",
    "article_authors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliated_authors = article_authors.groupby('journal:string').agg({'author_list': \"sum\"})\n",
    "affiliated_authors[\"author_list\"] = affiliated_authors[\"author_list\"].apply(lambda x: set(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31736\n"
     ]
    }
   ],
   "source": [
    "affiliated_authors_dict = affiliated_authors.to_dict(\"index\")\n",
    "all_authors = set()\n",
    "\n",
    "for key, v in affiliated_authors_dict.items():\n",
    "    all_authors = all_authors.union(v[\"author_list\"])\n",
    "\n",
    "print(len(all_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Key:\n",
    "    PREVIOUS_KEY = \"Comput. Chem. Eng.\"\n",
    "\n",
    "def get_reviewers(key):\n",
    "    try:\n",
    "        author_sample = random.sample(affiliated_authors_dict[key][\"author_list\"], 5)\n",
    "        Key.PREVIOUS_KEY = key\n",
    "    except ValueError:\n",
    "        author_sample = random.sample(affiliated_authors_dict[Key.PREVIOUS_KEY][\"author_list\"], 5)\n",
    "    \n",
    "    return set(author_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_53740\\1130410631.py:6: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  author_sample = random.sample(affiliated_authors_dict[key][\"author_list\"], 5)\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_53740\\1130410631.py:9: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  author_sample = random.sample(affiliated_authors_dict[Key.PREVIOUS_KEY][\"author_list\"], 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>journal:string</th>\n",
       "      <th>author_list</th>\n",
       "      <th>reviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Sven Lorenz, Toni Bollinger, Udo Pletat]</td>\n",
       "      <td>{Hans-Joachim Novak, Gert Smolka, Karl-Hans Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Text Understanding in LILOG</td>\n",
       "      <td>[Geoffrey Simmons, Kai-Uwe Carstensen]</td>\n",
       "      <td>{Gregor Erbach, Gudrun Klose, Bernd Walter, Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>journals/lncs/FlaterY93</td>\n",
       "      <td>Advanced Database Systems</td>\n",
       "      <td>[David W. Flater, Yelena Yesha]</td>\n",
       "      <td>{H. V. Jagadish, Martin Andersson, Yelena Yesh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key:string               journal:string  \\\n",
       "2  journals/lncs/BollingerLP91  Text Understanding in LILOG   \n",
       "3  journals/lncs/CarstensenS91  Text Understanding in LILOG   \n",
       "4      journals/lncs/FlaterY93    Advanced Database Systems   \n",
       "\n",
       "                                 author_list  \\\n",
       "2  [Sven Lorenz, Toni Bollinger, Udo Pletat]   \n",
       "3     [Geoffrey Simmons, Kai-Uwe Carstensen]   \n",
       "4            [David W. Flater, Yelena Yesha]   \n",
       "\n",
       "                                           reviewers  \n",
       "2  {Hans-Joachim Novak, Gert Smolka, Karl-Hans Bl...  \n",
       "3  {Gregor Erbach, Gudrun Klose, Bernd Walter, Di...  \n",
       "4  {H. V. Jagadish, Martin Andersson, Yelena Yesh...  "
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get sample of affiliated reviewers\n",
    "article_authors[\"reviewers\"] = article_authors[\"journal:string\"].apply(lambda x: get_reviewers(x))\n",
    "article_authors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove paper authors from reviewers\n",
    "article_authors[\"reviewers\"] = article_authors.apply(lambda row: row[\"reviewers\"].difference(set(row[\"author_list\"])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random reviewers where not enough\n",
    "def make_reviewers(current_reviewers:set, authors:set, journal:str):\n",
    "    no_reviewers = get_reviewer_count(journal)\n",
    "\n",
    "    while len(current_reviewers) < no_reviewers:\n",
    "        #add new sample\n",
    "        current_reviewers = current_reviewers.union(set(random.sample(all_authors, 1)))\n",
    "        #remove current authors\n",
    "        current_reviewers = current_reviewers.difference(authors)\n",
    "\n",
    "    if len(current_reviewers) >no_reviewers:\n",
    "        current_reviewers = set(random.sample(current_reviewers, no_reviewers))\n",
    "\n",
    "    return current_reviewers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_53740\\2002427380.py:12: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  current_reviewers = set(random.sample(current_reviewers, no_reviewers))\n",
      "C:\\Users\\schmi\\AppData\\Local\\Temp\\ipykernel_53740\\2002427380.py:7: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  current_reviewers = current_reviewers.union(set(random.sample(all_authors, 1)))\n"
     ]
    }
   ],
   "source": [
    "article_authors[\"reviewers\"] = article_authors.apply(lambda row: make_reviewers(row[\"reviewers\"], set(row[\"author_list\"]), row[\"journal:string\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key:string</th>\n",
       "      <th>reviewers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Petra Steffens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Karl-Hans Bläsius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>journals/lncs/BollingerLP91</td>\n",
       "      <td>Gert Smolka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Bernd Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>journals/lncs/CarstensenS91</td>\n",
       "      <td>Dieter Landes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    key:string          reviewers\n",
       "2  journals/lncs/BollingerLP91     Petra Steffens\n",
       "2  journals/lncs/BollingerLP91  Karl-Hans Bläsius\n",
       "2  journals/lncs/BollingerLP91        Gert Smolka\n",
       "3  journals/lncs/CarstensenS91       Bernd Walter\n",
       "3  journals/lncs/CarstensenS91      Dieter Landes"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewers = article_authors[[\"key:string\", \"reviewers\"]].explode(\"reviewers\")\n",
    "reviewers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['acceptance', 'outright rejection', 'conditional acceptance',\n",
       "       'conditional rejection'], dtype=object)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewers[\"review_text\"] = reviewers[\"reviewers\"].apply(lambda x: lipsum.generate_words(30))\n",
    "reviewers[\"suggested_decision\"] = reviewers[\"review_text\"].apply(lambda x: random.sample([\"acceptance\", \"conditional acceptance\", \"conditional rejection\", \"outright rejection\"],1)[0] if random.randint(1,10) < 2 else \"acceptance\")\n",
    "\n",
    "reviewers[\"suggested_decision\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers[\"supports_acceptance\"] = reviewers[\"suggested_decision\"].apply(lambda x : x in [\"acceptance\", \"conditional acceptance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56250"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acceptance_statistic = reviewers.groupby([\"key:string\"]).agg(acceptance_count=(\"supports_acceptance\",\"sum\"), no_reviewers=(\"reviewers\", \"count\"))\n",
    "acceptance_statistic[\"accepted\"] = acceptance_statistic[\"acceptance_count\"] > acceptance_statistic[\"no_reviewers\"]/2\n",
    "#acceptance_statistic[acceptance_statistic[\"accepted\"] == False]\n",
    "len(reviewers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewers.to_csv(\"data/reviewers.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affiliations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_list</th>\n",
       "      <th>affiliation</th>\n",
       "      <th>organization_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Hugo Hellebrand</td>\n",
       "      <td>Company 20</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Markus Casper</td>\n",
       "      <td>University 20</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Ralf Merz</td>\n",
       "      <td>Company 16</td>\n",
       "      <td>Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>Rita Ley</td>\n",
       "      <td>University 2</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Markus Tresch</td>\n",
       "      <td>University 17</td>\n",
       "      <td>University</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author_list    affiliation organization_type\n",
       "558  Hugo Hellebrand     Company 20           Company\n",
       "558    Markus Casper  University 20        University\n",
       "558        Ralf Merz     Company 16           Company\n",
       "558         Rita Ley   University 2        University\n",
       "562    Markus Tresch  University 17        University"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affiliations = pd.concat([articles[[\"author_list\"]], inproceedings[[\"author_list\"]]])\n",
    "affiliations = affiliations.explode(\"author_list\")\n",
    "affiliations[\"affiliation\"] = affiliations[\"author_list\"].apply(generate_affiliation)\n",
    "affiliations[\"organization_type\"] = affiliations[\"affiliation\"].apply(lambda x: x.split(\" \")[0])\n",
    "affiliations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliations.to_csv(\"data/affiliations.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful resources\n",
    "import guide: https://neo4j.com/developer/desktop-csv-import/ -> access import folder via UI -> DB -> Open folder -> import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "## Initial setup\n",
    "\n",
    "Most things will be done via the Python Neo4j API. However, a few steps were taken before:\n",
    "1. creation of the db via the UI. Name:publication-graph, PW: publication-graph\n",
    "2. started db via the UI\n",
    "3. preprocessed files for import placed in the respective input folder of the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set connection variables\n",
    "PORT = \"7687\" #database running on this port for bolt connections\n",
    "USER = \"neo4j\" #standard user\n",
    "PASSWORD = \"publication-graph\" #db password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: Connected to the Neo4j Database.\n"
     ]
    }
   ],
   "source": [
    "#connect to database\n",
    "try:\n",
    "    graph = Graph('bolt://localhost:'+PORT, auth=(USER, PASSWORD))\n",
    "    print('SUCCESS: Connected to the Neo4j Database.')\n",
    "except Exception as e:\n",
    "    print('ERROR: Could not connect to the Neo4j Database. See console for details.')\n",
    "    raise SystemExit(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query:str):\n",
    "    try:\n",
    "        return graph.run(query)\n",
    "    except ClientError as e:\n",
    "        print(e.message)\n",
    "\n",
    "def _reset_graph():\n",
    "    q = \"\"\"\n",
    "        call{\n",
    "        Match (n)\n",
    "        detach delete n} in transactions\n",
    "    \"\"\"\n",
    "    return run_query(q)\n",
    "\n",
    "def _find_import_problems():\n",
    "    q = \"\"\"\n",
    "    MATCH (n) WHERE size(labels(n)) = 0 RETURN n\n",
    "    \"\"\"\n",
    "\n",
    "    return run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_reset_graph()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create constraints \n",
    "- to increase performance during loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\" \n",
    "\n",
    "//Create constraints on the identifiers of the nodes\n",
    "\n",
    "CREATE CONSTRAINT FOR (p:Paper) REQUIRE p.paper_key IS UNIQUE;\n",
    "CREATE CONSTRAINT FOR (r:Researcher) REQUIRE r.name IS UNIQUE;\n",
    "CREATE CONSTRAINT FOR (j:Journal) REQUIRE j.journal_name IS UNIQUE;\n",
    "CREATE CONSTRAINT FOR (v:Volume) REQUIRE v.volume_key IS UNIQUE;\n",
    "CREATE CONSTRAINT FOR (k:Keyword) REQUIRE k.keyword IS UNIQUE;\n",
    "CREATE CONSTRAINT FOR (ce:ConferenceEdition) REQUIRE ce.conference_edition_key IS UNIQUE;\n",
    "CREATE CONSTRAINT for (c:Conference) require c.conference_name is unique;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An equivalent constraint already exists, 'Constraint( id=4, name='constraint_a7d3fea0', type='UNIQUENESS', schema=(:Paper {paper_key}), ownedIndex=3 )'.\n",
      "An equivalent constraint already exists, 'Constraint( id=6, name='constraint_c5e92188', type='UNIQUENESS', schema=(:Researcher {name}), ownedIndex=5 )'.\n",
      "An equivalent constraint already exists, 'Constraint( id=8, name='constraint_c8139076', type='UNIQUENESS', schema=(:Journal {journal_name}), ownedIndex=7 )'.\n",
      "An equivalent constraint already exists, 'Constraint( id=10, name='constraint_10a078f', type='UNIQUENESS', schema=(:Volume {volume_key}), ownedIndex=9 )'.\n",
      "An equivalent constraint already exists, 'Constraint( id=12, name='constraint_b93297e0', type='UNIQUENESS', schema=(:Keyword {keyword}), ownedIndex=11 )'.\n",
      "An equivalent constraint already exists, 'Constraint( id=14, name='constraint_6460932c', type='UNIQUENESS', schema=(:ConferenceEdition {conference_edition_key}), ownedIndex=13 )'.\n",
      "An equivalent constraint already exists, 'Constraint( id=16, name='constraint_438d01a5', type='UNIQUENESS', schema=(:Conference {conference_name}), ownedIndex=15 )'.\n",
      "Unexpected end of input: expected CYPHER, EXPLAIN, PROFILE or Query (line 0, column 1 (offset: 1))\n",
      "\"\"\n",
      " ^\n"
     ]
    }
   ],
   "source": [
    "constraints = QUERY_1.split(\";\")\n",
    "\n",
    "try:\n",
    "    \n",
    "    for c in constraints:\n",
    "        run_query(c)\n",
    "\n",
    "except ClientError as e:\n",
    "    print(e.message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load information from articles file\n",
    "This query loads most nodes from the articles csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2 = \"\"\"\n",
    "Load csv with headers from\n",
    "'file:///articles_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "with line\n",
    "\n",
    "MERGE (paper:Paper {paper_key: line.`key:string`})\n",
    "  ON CREATE\n",
    "    SET paper.title = line.`title:string`\n",
    "    SET paper.doi = line.doi\n",
    "\n",
    "MERGE (volume:Volume {volume_key:line.`crossref:string`})\n",
    "  ON CREATE\n",
    "    SET volume.year = line.`year:int`,\n",
    "        volume.volume_no = line.`number:string`,\n",
    "        volume.consecutive_issue_no = line.`volume:string`\n",
    "\n",
    "WITH line, SPLIT(line.keywords, '|') as keywords\n",
    "  UNWIND keywords as kw\n",
    "    MERGE (keyword:Keyword {keyword:kw})\n",
    "\n",
    "WITH line\n",
    "MERGE (journal:Journal {journal_name: line.`journal:string`})\n",
    "set journal.publisher = line.publisher\n",
    "\n",
    "WITH line, SPLIT(line.`author:string[]`, '|') as authors\n",
    "  UNWIND authors as a\n",
    "  MERGE (author:Researcher {name:a})\n",
    "\n",
    "} in transactions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(QUERY_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This query creates the author of relationship\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "Load csv with headers from\n",
    "'file:///articles_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "\n",
    "  WITH line\n",
    "  WITH line, SPLIT(line.`author:string[]`, '|') as authors\n",
    "  UNWIND authors as a\n",
    "  Match (r:Researcher {name:a}), (paper:Paper {paper_key: line.`key:string`})\n",
    "  MERGE (r)-[:AUTHOR_OF]->(paper)\n",
    "\n",
    "}in transactions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(QUERY_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set corresponding author\n",
    "QUERY_4 = \"\"\"\n",
    "Load csv with headers from\n",
    "'file:///articles_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "  with line\n",
    "  match (r:Researcher {name:line.corresponding_author}),(paper:Paper {paper_key: line.`key:string`})\n",
    "  Merge (r)-[authorof:AUTHOR_OF]->(paper)\n",
    "  Set authorof.corresponding_author = true\n",
    "}in transactions\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(QUERY_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#published in relationship, issues relationship, main topic relationship\n",
    "QUERY_5 =\"\"\"\n",
    "Load csv with headers from\n",
    "  'file:///articles_preprocessed.csv' AS line\n",
    "\n",
    "    FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "  with line\n",
    "  Match (p:Paper {paper_key: line.`key:string`}), (volume:Volume {volume_key:line.`crossref:string`}), (journal:Journal {journal_name: line.`journal:string`})\n",
    "  Merge  (p)- [publishedin:PUBLISHED_IN] -> (volume)\n",
    "    ON CREATE\n",
    "      Set publishedin.pages = line.`pages:string`\n",
    "\n",
    "  Merge  (journal)-[:ISSUES] ->(volume)\n",
    "\n",
    "  WITH line, SPLIT(line.keywords, '|') as keywords, p\n",
    "  Unwind keywords as kw\n",
    "    Match (k:Keyword {keyword:kw})\n",
    "    Merge (p)-[:MAIN_TOPIC]->(k)\n",
    "\n",
    "}in TRANSACTIONS\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(QUERY_5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load information from inproceedings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_QUERY_1 = \"\"\"\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///inproceedings_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "call{\n",
    "    with line\n",
    "    Merge (paper:Paper {paper_key: line.`key:string`})\n",
    "    set paper.title = coalesce(paper.title, line.`title:string`)\n",
    "\n",
    "    with line, paper\n",
    "    Merge (ce:ConferenceEdition {conference_edition_key: line.`crossref:string[]`})\n",
    "    Set ce.year_held = coalesce(ce.year_held, line.year)\n",
    "\n",
    "    with line, ce,paper\n",
    "    merge (c:Conference {conference_name:line.`booktitle:string`})\n",
    "    merge (c)-[:HOLDS]->(ce)\n",
    "\n",
    "    WITH line, SPLIT(line.keywords, '|') as keywords,paper\n",
    "    Unwind keywords as kw\n",
    "    MERGE (keyword:Keyword {keyword:kw})\n",
    "    \n",
    "    with line, keyword,paper\n",
    "    MERGE (paper)-[:MAIN_TOPIC]->(keyword)\n",
    "\n",
    "    WITH line, SPLIT(line.`author:string[]`, '|') as authors, paper\n",
    "    unwind authors as a\n",
    "    MERGE (author:Researcher {name:a})\n",
    "    Merge (author)-[:AUTHOR_OF]->(paper)\n",
    "\n",
    "\n",
    "\n",
    "}in transactions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(IP_QUERY_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "IP_QUERY_2 = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///inproceedings_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "call{\n",
    "    with line\n",
    "    match (ce:ConferenceEdition {conference_edition_key: line.`crossref:string[]`}),(paper:Paper {paper_key: line.`key:string`})\n",
    "    merge (paper)-[pi:PUBLISHED_IN]-(ce)\n",
    "    set pi.pages = coalesce (pi.pages,line.`pages:string[]` )\n",
    "\n",
    "    with line, paper\n",
    "    Match (r:Researcher {name:line.corresponding_author})\n",
    "    Merge (r)-[authorof:AUTHOR_OF]->(paper)\n",
    "    Set authorof.corresponding_author = true\n",
    "}in transactions\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(IP_QUERY_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load citation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_QUERY_1 = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///citations.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "\n",
    "    with line\n",
    "    with line, SPLIT(line.cites, '|') as citations\n",
    "\n",
    "    unwind citations as c\n",
    "    Match (paper:Paper {paper_key:line.`key:string`}), (p:Paper {paper_key:c})\n",
    "    Merge (paper)-[:CITES]->(p)\n",
    "\n",
    "}in transactions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(C_QUERY_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load Auxiliary Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_QUERY_1_COMPOSED = \"\"\"\n",
    "//Publications of a journal\n",
    "Match (p:Paper)-[:PUBLISHED_IN]->(v:Volume)<-[:ISSUES]-(j:Journal)\n",
    "Merge (p)<-[pub:JOURNAL_PUBLICATION]-(j)\n",
    "Set pub.year = v.year;\n",
    "\n",
    "\n",
    "//Citation Count Aid\n",
    "Match (v1:Volume)<-[:PUBLISHED_IN]-(p1:Paper)-[:CITES]->(p2:Paper)-[:PUBLISHED_IN]->(:Volume)<-[:ISSUES]-(j:Journal)\n",
    "Merge (p1)-[cit:JOURNAL_CITATION]->(j)\n",
    "Set cit.year = v1.year\n",
    "\"\"\"\n",
    "A_QUERY_2 =\"\"\"\n",
    "//chairs and editors\n",
    "Load csv with headers from\n",
    "    'file:///editors.csv' AS line\n",
    "\n",
    "    FIELDTERMINATOR ','\n",
    "\n",
    "    call{\n",
    "with line\n",
    "Match(j:Journal {journal_name: line.`journal:string`}), (r:Researcher {name: line.author_list})\n",
    "Merge (r)-[:EDITOR]-(j)\n",
    "\n",
    "}in transactions;\n",
    "\"\"\"\n",
    "\n",
    "A_QUERY_3 =\"\"\"\n",
    "//chairs and editors\n",
    "Load csv with headers from\n",
    "    'file:///conference_chairs.csv' AS line\n",
    "\n",
    "    FIELDTERMINATOR ','\n",
    "\n",
    "    call{\n",
    "with line\n",
    "Match(ce:ConferenceEdition {conference_edition_key: line.`crossref:string[]`}), (r:Researcher {name: line.author_list})\n",
    "Merge (r)-[:CHAIRPERSON]-(ce)\n",
    "\n",
    "}in transactions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "A_QUERY_4 = \"\"\"\n",
    "//abstract same as title for now\n",
    "Match(n:Paper)\n",
    "Set n.abstract = n.title;\n",
    "\"\"\"\n",
    "\n",
    "A_QUERY_5 = \"\"\"\n",
    "//reviewers\n",
    "Load csv with headers from\n",
    "    'file:///reviewers.csv' AS line\n",
    "\n",
    "    FIELDTERMINATOR ','\n",
    "\n",
    "    call{\n",
    "      with line\n",
    "      Match (p:Paper {paper_key: line.`key:string`})<-[:JOURNAL_PUBLICATION]-(j:Journal) //\n",
    "      Merge (rev:Review)-[:REVIEW_SUBJECT]->(p)\n",
    "\n",
    "      with line, p, rev, j\n",
    "      Match (a:Researcher {name:line.reviewers})\n",
    "      Merge (a)-[:PARTICIPATES_IN]->(rev)\n",
    "      Merge (rev)-[:SUBMITTED_TO]->(j)\n",
    "\n",
    "    }in transactions;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "A_QUERY_6 = \"\"\"\n",
    "//reviewers\n",
    "Load csv with headers from\n",
    "    'file:///reviewers.csv' AS line\n",
    "\n",
    "    FIELDTERMINATOR ','\n",
    "\n",
    "    call{\n",
    "      with line\n",
    "      Match (p:Paper {paper_key: line.`key:string`})-[:PUBLISHED_IN]->(ce:ConferenceEdition)\n",
    "      Merge (rev:Review)-[:REVIEW_SUBJECT]->(p)\n",
    "      with line, p, rev, ce\n",
    "\n",
    "      Match (a:Researcher {name:line.reviewers})\n",
    "      Merge (a)-[:PARTICIPATES_IN]->(rev)\n",
    "      Merge (rev)-[:SUBMITTED_TO]->(ce)\n",
    "\n",
    "    }in transactions;\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q in A_QUERY_1_COMPOSED.split(\";\"):\n",
    "    run_query(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(A_QUERY_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(A_QUERY_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(A_QUERY_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(A_QUERY_5)\n",
    "run_query(A_QUERY_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load Proceeding informaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_QUERY_1 = \"\"\"\n",
    "\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///proceedings_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "    with line\n",
    "    MERGE(ce:ConferenceEdition {conference_edition_key: line.`key:string`})\n",
    "\n",
    "        SET ce.year_published = line.`year:int`,\n",
    "            ce.edition = line.edition,\n",
    "            ce.proceeding_title = line.`title:string`\n",
    "\n",
    "\n",
    "}in transactions   \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "P_QUERY_2 = \"\"\"\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///inproceedings_preprocessed.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "    with line\n",
    "    match (ce:ConferenceEdition {conference_edition_key: line.`crossref:string[]`})\n",
    "\n",
    "    set ce.year_held = coalesce(ce.year_held, tointeger(line.`year:int`))\n",
    "\n",
    "}in transactions\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(P_QUERY_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(P_QUERY_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "#ask about conference or proceeding\n",
    "# check journal_publication relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load review content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_CONTENT_QUERY = \"\"\"\n",
    "//reviewers\n",
    "Load csv with headers from\n",
    "'file:///reviewers.csv' AS line\n",
    "\n",
    "FIELDTERMINATOR ','\n",
    "\n",
    "    call{\n",
    "      with line\n",
    "      Match (paper:Paper {paper_key: line.`key:string`})<-[:REVIEW_SUBJECT]-(review:Review)\n",
    "      Match (r:Researcher {name: line.reviewers})-[pi:PARTICIPATES_IN]->(review)\n",
    "\n",
    "      Set pi.suggested_decision = line.suggested_decision,\n",
    "          pi.review_content = line.review_text,\n",
    "          pi.supports_acceptance = toBoolean(line.supports_acceptance)\n",
    "\n",
    "    }in transactions\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(REVIEW_CONTENT_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEW_DECISION_QUERY = \"\"\"\n",
    "\n",
    "match (r:Review)-[:REVIEW_SUBJECT]->(x:Paper), (r)<-[pi:PARTICIPATES_IN]-(:Researcher)\n",
    "with r,collect(pi) as reviews, count(pi) as total\n",
    "with r,reviews,total \n",
    "unwind reviews as review\n",
    "match ()-[review {supports_acceptance:TRUE}]->(r)\n",
    "with r, count(review) as subtotal, total\n",
    "with r, tofloat(subtotal) / total as acceptance_rate\n",
    "\n",
    "set r.decision = \n",
    "case acceptance_rate > 0.5\n",
    "when  TRUE then \"ACCEPTED\"\n",
    "    else \"REJECTED\" end\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "REMOVE_RELATED_RELATIONSHIPS = \"\"\"\n",
    "match (review:Review {decision:\"REJECTED\"})-[:REVIEW_SUBJECT]->(paper:Paper)\n",
    "optional match (paper)-[pi:PUBLISHED_IN]->()\n",
    "optional match (paper)<-[jp:JOURNAL_PUBLICATION]-(:Journal)\n",
    "optional match (paper)-[jc:JOURNAL_CITATION]->(:Journal)\n",
    "\n",
    "delete pi, jp, jc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_query(REVIEW_DECISION_QUERY)\n",
    "run_query(REMOVE_RELATED_RELATIONSHIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "organization_constraint = \"CREATE CONSTRAINT FOR (o:Organization) REQUIRE o.organization_name IS UNIQUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(organization_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "AFFILIATION = \"\"\"\n",
    "Load csv with headers from\n",
    "  'file:///affiliations.csv' AS line\n",
    "\n",
    "    FIELDTERMINATOR ','\n",
    "\n",
    "call{\n",
    "  with line\n",
    "  \n",
    "  Match (r:Researcher {name: line.author_list})\n",
    "  Merge (o:Organization {organization_name: line.affiliation})\n",
    "  set o.organization_type = line.organization_type\n",
    "\n",
    "  Merge (r)-[:AFFILIATED_WITH]->(o)\n",
    "  \n",
    "}in transactions\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "(No data)"
      ],
      "text/plain": [
       "(No data)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(AFFILIATION)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updated_journal citation relationship\n",
    "journal_citation =\"\"\"\n",
    "\n",
    "//publication year of the paper that is cited\n",
    "// year the citation happend\n",
    "\n",
    "Match(paper:Paper)-[:CITES]->(cited_paper:Paper),(cited_paper)-[:PUBLISHED_IN]->(volume:Volume),(cited_paper)<-[:JOURNAL_PUBLICATION]-(journal:Journal), (paper)-[:PUBLISHED_IN]-(pub), (paper)-[jc:JOURNAL_CITATION]->(journal)\n",
    "\n",
    "SET jc.year_cited = coalesce(pub.year, pub.year_published),\n",
    "    jc.publication_year_cited_paper = volume.year\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "impact_factor = \"\"\"\n",
    "//Impact factor (citations(year x) of papers published in last two year)/(publications in last two years)\n",
    "\n",
    "Match (:Paper)-[jc:JOURNAL_CITATION]->(journal:Journal)\n",
    "where jc.year_cited = <YEAR> AND (jc.publication_year_cited_paper=<YEAR-2> Or jc.publication_year_cited_paper=<YEAR-1>)\n",
    "with journal, count(jc) as no_citations\n",
    "\n",
    "match (:Paper)<-[jp:JOURNAL_PUBLICATION]-(journal)\n",
    "where jp.year = <YEAR-2> or jp.year = <YEAR-1>\n",
    "\n",
    "with journal, no_citations, count(jp) as no_publications\n",
    "return journal.journal_name, no_citations, no_publications, (tofloat(no_citations) / no_publications) as impact_factor\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impact_factor(year:int):\n",
    "    q = impact_factor.replace(\"<YEAR>\", str(year)).replace(\"<YEAR-1>\", str(year-1)).replace(\"<YEAR-2>\", str(year-2))\n",
    "\n",
    "    print(run_query(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " journal.journal_name | no_citations | no_publications |     impact_factor \n",
      "----------------------|--------------|-----------------|-------------------\n",
      " J. Econ. Theory      |          454 |             261 | 1.739463601532567 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_impact_factor(2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_index = \"\"\"\n",
    "Match (a:Researcher)-[ao:AUTHOR_OF]->(paper:Paper)\n",
    "optional match (paper)<-[ci:CITES]-(citing_paper:Paper)\n",
    "\n",
    "With  a, paper, count(citing_paper) as no_cit\n",
    "With a, collect([a,paper,no_cit]) as papers\n",
    "\n",
    "unwind range(0, size(papers)-1) as ind\n",
    "\n",
    "//where no_cit > no_pub\n",
    "\n",
    "with a, papers[ind][0] as auth, papers[ind][1] as pap,ind,papers[ind][2] as no_cit, case papers[ind][2] >= ind +1 when true then 1 else 0 end as in_count\n",
    "//where  no_cit >= ind +1\n",
    "//return a.name, pap.title, ind + 1 , no_cit, in_count\n",
    "order by ind desc, no_cit\n",
    "return a.name, sum( in_count) as h_index\n",
    "order by h_index desc\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = run_query(h_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cursor.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31729"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
